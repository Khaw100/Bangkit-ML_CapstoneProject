{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_qfzq2wDZmkx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import linregress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Vd4os3NhZp5l"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('ReviewsEN.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uQq0VQTZ9iF",
        "outputId": "fa1d770d-3c32-4e0e-8bea-ba61defc6409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1 : 870\n",
            "0 : 639\n",
            "1 : 1518\n"
          ]
        }
      ],
      "source": [
        "print(\"-1 :\", df['sentiment'].value_counts()[-1])\n",
        "print(\"0 :\", df['sentiment'].value_counts()[0])\n",
        "print(\"1 :\", df['sentiment'].value_counts()[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DsSXQdDXZ-0R"
      },
      "outputs": [],
      "source": [
        "# Replace values in pandas DataFrame.\n",
        "df['sentiment'] = df['sentiment'].replace([1], 2)\n",
        "df['sentiment'] = df['sentiment'].replace([0], 1)\n",
        "df['sentiment'] = df['sentiment'].replace([-1], 0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VeUKsk6Xc96m"
      },
      "source": [
        "## Case Folding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RayqsORYaBXV",
        "outputId": "f3dcefbc-f797-4ad6-edaf-9a56ff4fde3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      sentiment                                            reviews\n",
            "0             1  teacher are punctual but they should also give...\n",
            "1             2                                               good\n",
            "2             2  excellent lectures are delivered by teachers a...\n",
            "3             2  teachers give us all the information required ...\n",
            "4             2                                                yes\n",
            "...         ...                                                ...\n",
            "3022          2        lecturers provide clear enough explanations\n",
            "3023          2            lecturer's assessment is very objective\n",
            "3024          0              lecturers give very good explanations\n",
            "3025          0        lecturers often provoke discussion in class\n",
            "3026          2         lecturers provide material in a boring way\n",
            "\n",
            "[3027 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Apply lower function\n",
        "df['reviews'] = df['reviews'].apply(str.lower)\n",
        "print(df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GPHtwv2EdE9_"
      },
      "source": [
        "## Hyper Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xSDvqvHSeqFr"
      },
      "outputs": [],
      "source": [
        "# Global Variables\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "MAXLEN = 16\n",
        "TRUNCATING = 'post'\n",
        "PADDING = 'post'\n",
        "OOV_TOKEN = \"<OOV>\"\n",
        "MAX_EXAMPLES = len(df)\n",
        "TRAINING_SPLIT = 0.9"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yuvN6YvqdOr5"
      },
      "source": [
        "## Remove Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jlE8pTQ8c6e_"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Remove punctuation marks\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text_without_punctuation = text.translate(translator)\n",
        "    return text_without_punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4Se9P5ddTtG",
        "outputId": "5340a8e9-8dfc-4380-bbba-ec91fa815542"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['teacher are punctual but they should also give us the some practical knowledge other than theortical',\n",
              "       'good',\n",
              "       'excellent lectures are delivered by teachers and all teachers are very punctual',\n",
              "       ..., 'lecturers give very good explanations',\n",
              "       'lecturers often provoke discussion in class',\n",
              "       'lecturers provide material in a boring way'], dtype=object)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "removedPunctuation_text = []\n",
        "for i in range(len(df)):\n",
        "  removedPunctuation_text.append(remove_punctuation(df['reviews'][i]))\n",
        "\n",
        "df['reviews'] = removedPunctuation_text\n",
        "df['reviews'].values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wuUyzP-PdmZu"
      },
      "source": [
        "## Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvF7m92Li9iX",
        "outputId": "699c3736-c3de-4ec9-870f-fdbb15ae6ba2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')  \n",
        "nltk.download('punkt')  \n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = []\n",
        "    tokens = nltk.word_tokenize(text)  \n",
        "    for token in tokens:\n",
        "        lemma = lemmatizer.lemmatize(token) \n",
        "        lemmatized_words.append(lemma)\n",
        "    lemmatized_text = ' '.join(lemmatized_words)  \n",
        "    return lemmatized_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LzeSycQJjF83"
      },
      "outputs": [],
      "source": [
        "temp =  []\n",
        "for i in range(len(df)):\n",
        "  temp.append(lemmatize_text(df['reviews'][i]))\n",
        "df['reviews'] = temp"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Sk8mp7jdzH"
      },
      "source": [
        "## Convert Numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gsE6EaxtjiV_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_numbers(text):\n",
        "    cleaned_text = re.sub(r'\\d+', '', text)  \n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Wsfvp3VOj7Vm",
        "outputId": "61048f72-bbb3-49b7-b1a1-e7ee5b58a011"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-855a5541-6bea-4a10-acff-06a267f58ac2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>teacher are punctual but they should also give...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>excellent lecture are delivered by teacher and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>teacher give u all the information required to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3022</th>\n",
              "      <td>2</td>\n",
              "      <td>lecturer provide clear enough explanation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3023</th>\n",
              "      <td>2</td>\n",
              "      <td>lecturer assessment is very objective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>0</td>\n",
              "      <td>lecturer give very good explanation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3025</th>\n",
              "      <td>0</td>\n",
              "      <td>lecturer often provoke discussion in class</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3026</th>\n",
              "      <td>2</td>\n",
              "      <td>lecturer provide material in a boring way</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3027 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-855a5541-6bea-4a10-acff-06a267f58ac2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-855a5541-6bea-4a10-acff-06a267f58ac2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-855a5541-6bea-4a10-acff-06a267f58ac2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      sentiment                                            reviews\n",
              "0             1  teacher are punctual but they should also give...\n",
              "1             2                                               good\n",
              "2             2  excellent lecture are delivered by teacher and...\n",
              "3             2  teacher give u all the information required to...\n",
              "4             2                                                yes\n",
              "...         ...                                                ...\n",
              "3022          2          lecturer provide clear enough explanation\n",
              "3023          2              lecturer assessment is very objective\n",
              "3024          0                lecturer give very good explanation\n",
              "3025          0         lecturer often provoke discussion in class\n",
              "3026          2          lecturer provide material in a boring way\n",
              "\n",
              "[3027 rows x 2 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['reviews'] = df['reviews'].apply(remove_numbers)\n",
        "df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XJPg4SNldKo-"
      },
      "source": [
        "## Random Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm_QQl4setsh",
        "outputId": "26c1f1f5-4088-4684-a5b8-9defb4bcfe3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 3027 sentences and 3027 labels after random sampling\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "# Get the indices of the DataFrame\n",
        "indices = df.index.tolist()\n",
        "\n",
        "# Perform random sampling on the indices\n",
        "selected_indices = random.sample(indices, MAX_EXAMPLES)\n",
        "\n",
        "# Select the corresponding sentences and labels based on the sampled indices\n",
        "sentences = df.loc[selected_indices, 'reviews']\n",
        "labels = df.loc[selected_indices, 'sentiment']\n",
        "\n",
        "print(f\"There are {len(sentences)} sentences and {len(labels)} labels after random sampling\\n\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XBbquN0qf6Og"
      },
      "source": [
        "# Training - Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BSptFFxJf8hw"
      },
      "outputs": [],
      "source": [
        "def train_val_split(sentences, labels, training_split):\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Compute the number of sentences that will be used for training (should be an integer)\n",
        "    train_size = int(len(sentences)*training_split)\n",
        "\n",
        "    # Split the sentences and labels into train/validation splits\n",
        "    train_sentences = sentences[:train_size]\n",
        "    train_labels = labels[:train_size]\n",
        "\n",
        "    test_sentences = sentences[train_size:]\n",
        "    test_labels = labels[train_size:]\n",
        "    \n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return train_sentences, test_sentences, train_labels, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbdiZp4LgHwo",
        "outputId": "234291a5-b44b-4994-de0f-a662c15ca7f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2724 sentences for training.\n",
            "\n",
            "There are 2724 labels for training.\n",
            "\n",
            "There are 303 sentences for validation.\n",
            "\n",
            "There are 303 labels for validation.\n"
          ]
        }
      ],
      "source": [
        "train_sentences, test_sentences, train_labels, test_labels = train_val_split(sentences, labels, TRAINING_SPLIT)\n",
        "\n",
        "print(f\"There are {len(train_sentences)} sentences for training.\\n\")\n",
        "print(f\"There are {len(train_labels)} labels for training.\\n\")\n",
        "print(f\"There are {len(test_sentences)} sentences for validation.\\n\")\n",
        "print(f\"There are {len(test_labels)} labels for validation.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkha78ZLhD8n"
      },
      "source": [
        "# Tokenization & Stopwords - Sequences, Truncating, and Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKC0bOvTe0tc",
        "outputId": "a27d7837-b182-4e74-876b-11e58001c739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k09AYA_Vn2qS"
      },
      "source": [
        "#### Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUXhqbqynJcz",
        "outputId": "acde5318-dabb-4888-8d3d-8633000072a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'about', 'above', 'across', 'after', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'among', 'an', 'and', 'another', 'any', 'anybody', 'anyone', 'anything', 'anywhere', 'are', 'area', 'areas', 'around', 'as', 'ask', 'asked', 'asking', 'asks', 'at', 'away', 'b', 'back', 'backed', 'backing', 'backs', 'be', 'became', 'because', 'become', 'becomes', 'been', 'before', 'began', 'behind', 'being', 'beings', 'best', 'better', 'between', 'big', 'both', 'but', 'by', 'c', 'came', 'can', 'cannot', 'case', 'cases', 'certain', 'certainly', 'clear', 'clearly', 'come', 'could', 'd', 'did', 'differ', 'different', 'differently', 'do', 'does', 'done', 'down', 'down', 'downed', 'downing', 'downs', 'during', 'e', 'each', 'early', 'either', 'end', 'ended', 'ending', 'ends', 'enough', 'even', 'evenly', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'f', 'face', 'faces', 'fact', 'facts', 'far', 'felt', 'few', 'find', 'finds', 'first', 'for', 'four', 'from', 'full', 'fully', 'further', 'furthered', 'furthering', 'furthers', 'g', 'gave', 'general', 'generally', 'get', 'gets', 'give', 'given', 'gives', 'go', 'going', 'good', 'goods', 'got', 'great', 'greater', 'greatest', 'group', 'grouped', 'grouping', 'groups', 'h', 'had', 'has', 'have', 'having', 'he', 'her', 'here', 'herself', 'high', 'high', 'high', 'higher', 'highest', 'him', 'himself', 'his', 'how', 'however', 'i', 'if', 'important', 'in', 'interest', 'interested', 'interesting', 'interests', 'into', 'is', 'it', 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps', 'kind', 'knew', 'know', 'known', 'knows', 'l', 'large', 'largely', 'last', 'later', 'latest', 'least', 'less', 'let', 'lets', 'like', 'likely', 'long', 'longer', 'longest', 'm', 'made', 'make', 'making', 'man', 'many', 'may', 'me', 'member', 'members', 'men', 'might', 'more', 'most', 'mostly', 'mr', 'mrs', 'much', 'must', 'my', 'myself', 'n', 'necessary', 'need', 'needed', 'needing', 'needs', 'never', 'new', 'new', 'newer', 'newest', 'next', 'no', 'nobody', 'non', 'noone', 'not', 'nothing', 'now', 'nowhere', 'number', 'numbers', 'o', 'of', 'off', 'often', 'old', 'older', 'oldest', 'on', 'once', 'one', 'only', 'open', 'opened', 'opening', 'opens', 'or', 'order', 'ordered', 'ordering', 'orders', 'other', 'others', 'our', 'out', 'over', 'p', 'part', 'parted', 'parting', 'parts', 'per', 'perhaps', 'place', 'places', 'point', 'pointed', 'pointing', 'points', 'possible', 'present', 'presented', 'presenting', 'presents', 'problem', 'problems', 'put', 'puts', 'q', 'quite', 'r', 'rather', 'really', 'right', 'right', 'room', 'rooms', 's', 'said', 'same', 'saw', 'say', 'says', 'second', 'seconds', 'see', 'seem', 'seemed', 'seeming', 'seems', 'sees', 'several', 'shall', 'she', 'should', 'show', 'showed', 'showing', 'shows', 'side', 'sides', 'since', 'small', 'smaller', 'smallest', 'so', 'some', 'somebody', 'someone', 'something', 'somewhere', 'state', 'states', 'still', 'still', 'such', 'sure', 't', 'take', 'taken', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'these', 'they', 'thing', 'things', 'think', 'thinks', 'this', 'those', 'though', 'thought', 'thoughts', 'three', 'through', 'thus', 'to', 'today', 'together', 'too', 'took', 'toward', 'turn', 'turned', 'turning', 'turns', 'two', 'u', 'under', 'until', 'up', 'upon', 'us', 'use', 'used', 'uses', 'v', 'very', 'w', 'want', 'wanted', 'wanting', 'wants', 'was', 'way', 'ways', 'we', 'well', 'wells', 'went', 'were', 'what', 'when', 'where', 'whether', 'which', 'while', 'who', 'whole', 'whose', 'why', 'will', 'with', 'within', 'without', 'work', 'worked', 'working', 'works', 'would', 'x', 'y', 'year', 'years', 'yet', 'you', 'young', 'younger', 'youngest', 'your', 'yours', 'z', '']\n"
          ]
        }
      ],
      "source": [
        "my_file = open(\"stopwords.txt\", \"r\")\n",
        "  \n",
        "data = my_file.read()\n",
        "  \n",
        "stopwords_data = data.split(\"\\n\")\n",
        "print(stopwords_data)\n",
        "my_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0jSROBdBn92J"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(sentence, data):\n",
        "    # List of stopwords\n",
        "\n",
        "    stopwords = data + [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "    numbers_stopwords = [\"1\", \"2\", \"3\", \"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\n",
        "                         \"one\", \"two\",\"three\",\"four\",\"five\",\"098\"]\n",
        "    more_words = [\"didn't\", \"don't\", \"dont\", \"didnt\", \"it\", \"doesnt\", \"doesn't\", \"hw\",\"won't\",\"lpu\",\"weren't\",\"mr\",\"mcq\",\"shes\",\n",
        "                  \"shes\",\"india\",\"in\",\"hes\",\"shes\",\"me\", \"dr\", \"nlandu\", \"ko\",\"it\",\"1st\", \"omr\", \"ha\", \"upto\",\"ca\", \"soo\", \"cd\", \"ive\",\"po\",\"cse\", \"chem\", \"un\",\"of\",\n",
        "                  \"mte\", \"omr\",\"mte's\",\"ca's\",\"ete's\",\"jnv\",\"ip\",\"sir\",\"its\",\"wks\",\"prob\",\"python\",\"java\",\"lattc\",\"ol\",\"ived\",\"elsewhere\", \"mother\",\"wouldnt\",\"car\",\n",
        "                  \"si\", \"sat\",\"we\",\"home\",\"hot\",\"god\",\"ice\",\"money's\",\"money\",\"even\",\"about\",\"thats\", \"wks\", \"thurs\", \"months\", \"sir\", \"go\", \"jnv\", \"ip\", \"today\", \"today's\", \"linux\", \"github\",\n",
        "                  \"lt\", \"ums\", \"superb\", \"at\", \"cgpa\",\"ques\", \"brain's\", \"mcqs\", \"ve\", \"say\", \"pc\", \"viva\", \"after\", \"before\", \"draw\", \"asst\", \"only\", \"rich\", \"never\", \"went\", \"pcs\", \"gk\", \"one's\",\n",
        "                  \"co\", \"duty\", \"gona\", \"attendnce\",\"same\", \"that's\", \"hahahah\", \"ad's\", \"university's\", \"relly\", \"build\", \"cricket\", \"said\", \"hall\", \"profs\", \"guy's\", \"can\", \"along\", \"archieve\", \"bag\",\n",
        "                  \"part\", \"master\", \"push\", \"or\", \"add\", \"were\", \"virginia\",\"human\", \"bless\", \"clean\", \"count\", \"onlineopen\", \"ounce\", \"brushing\", \"zero\", \"mail\", \"fys\", \"lowell\", \"stets\", \"untill\", \"until\",\n",
        "                  \"prep\", \"appears\", \"giulia\", \"yuk\", \"memo\", \"ton\", \"110q\", \"unit\", \"80\",\"re\",\"by\",\"order\",\"fob\", \"sit\", \"from\",\"art\", \"org\", \"4d\", \"3d\", \"cinema\", \"iii\", \"cal\", \"both\", \"sundays\", \"todays\", \"ad\",\n",
        "                  \"yoursel\",\"yourself\", \"kiss\", \"it'll\", \"obayani's\", \"anal\", \"pgs\", \"csci\", \"hw\", \"more\", \"able\", \"lecturer\", \"lecturer's\", \"student\", \"stundet's\", \"it\", \"want\", \"you\",\"he's\", \"she's\"]\n",
        "    more =  [\n",
        "    'a', 'about', 'above', 'after', 'again', 'against', \"ain't\", 'all', 'am', 'an', 'and', 'any', 'are', 'aren\\'t', 'as', \n",
        "    'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'can\\'t', 'cannot', \n",
        "    'could', 'couldn\\'t', 'did', 'didn\\'t', 'do', 'does', 'doesn\\'t', 'doing', 'don\\'t', 'down', 'during', 'each', 'few', \n",
        "    'for', 'from', 'further', 'had', 'hadn\\'t', 'has', 'hasn\\'t', 'have', 'haven\\'t', 'having', 'he', 'he\\'d', 'he\\'ll', \n",
        "    'he\\'s', 'her', 'here', 'here\\'s', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'how\\'s', 'i', 'i\\'d', 'i\\'ll', \n",
        "    'i\\'m', 'i\\'ve', 'if', 'in', 'into', 'is', 'isn\\'t', 'it', 'it\\'s', 'its', 'itself', 'let\\'s', 'me', 'more', 'most', \n",
        "    'mustn\\'t', 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', \n",
        "    'ours', 'ourselves', 'out', 'over', 'own', 'same', 'shan\\'t', 'she', 'she\\'d', 'she\\'ll', 'she\\'s', 'should', \n",
        "    'shouldn\\'t', 'so', 'some', 'such', 'than', 'that', 'that\\'s', 'the', 'their', 'theirs', 'them', 'themselves', \n",
        "    'then', 'there', 'there\\'s', 'these', 'they', 'they\\'d', 'they\\'ll', 'they\\'re', 'they\\'ve', 'this', 'those', \n",
        "    'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', 'wasn\\'t', 'we', 'we\\'d', 'we\\'ll', 'we\\'re', \n",
        "    'we\\'ve', 'were', 'weren\\'t', 'what', 'what\\'s', 'when', 'when\\'s', 'where', 'where\\'s', 'which', 'while', 'who', \n",
        "    'who\\'s', 'whom', 'why', 'why\\'s', 'with', 'won\\'t', 'would', 'wouldn\\'t', 'you', 'you\\'d', 'you\\'ll', 'you\\'re', \n",
        "    'you\\'ve', 'your', 'yours', 'yourself', 'yourselves']\n",
        "\n",
        "    final_stopwords = stopwords + numbers_stopwords + more_words + more\n",
        "\n",
        "    words = sentence.split()\n",
        "    tempWords = []\n",
        "    for i in words:\n",
        "        if i not in final_stopwords:\n",
        "            tempWords.append(i)\n",
        "            sentence = ' '.join(tempWords)\n",
        "    \n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ0o7mPbolbS",
        "outputId": "6aa177d0-e13e-4f6f-ed57-3bded07501b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')  \n",
        "nltk.download('stopwords')  \n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words_list = list(stop_words)\n",
        "stopwords_data = stopwords_data + stop_words_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzoVVl0Sq723",
        "outputId": "a0bb510b-4f1a-4489-ae61-eb7b5b291bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')  \n",
        "response = vectorizer.fit_transform(df['reviews'])\n",
        "print(type(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OVLg8mUcoQGS"
      },
      "outputs": [],
      "source": [
        "cKomen = []\n",
        "for i in range(len(df)):\n",
        "  cKomen.append(remove_stopwords(df['reviews'][i], stopwords_data))\n",
        "\n",
        "df['reviews'] = cKomen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ysf5VZ_hhITo"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: fit_tokenizer\n",
        "def fit_tokenizer(sentences, oov_token):\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Instantiate the Tokenizer class, passing in the correct values for oov_token\n",
        "    tokenizer = Tokenizer(oov_token = OOV_TOKEN)\n",
        "    \n",
        "    # Fit the tokenizer to the training sentences\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hy5fTzvhMMm",
        "outputId": "cdd780de-2faf-4574-e627-ec7e5ee24d39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary contains 3669 words\n",
            "\n",
            "<OOV> token included in vocabulary\n",
            "\n",
            "index of word 'i' should be 10\n"
          ]
        }
      ],
      "source": [
        "# Test your function\n",
        "tokenizer = fit_tokenizer(train_sentences, OOV_TOKEN)\n",
        "word_index = tokenizer.word_index\n",
        "VOCAB_SIZE = len(word_index)\n",
        "\n",
        "print(f\"Vocabulary contains {VOCAB_SIZE} words\\n\")\n",
        "print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")\n",
        "print(f\"\\nindex of word 'i' should be {word_index['i']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xUkJFtiwh7C-"
      },
      "outputs": [],
      "source": [
        "def seq_pad_and_trunc(sentences, tokenizer, padding, truncating, maxlen):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    pad_trunc_sequences = pad_sequences(sequences, maxlen= MAXLEN, padding = PADDING, truncating = TRUNCATING)\n",
        "    return pad_trunc_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biCCj27uh-Ve",
        "outputId": "16b0378b-ae59-4895-8cc2-47cab718b1ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padded and truncated training sequences have shape: (2724, 16)\n",
            "\n",
            "Padded and truncated validation sequences have shape: (303, 16)\n"
          ]
        }
      ],
      "source": [
        "train_pad_trunc_seq = seq_pad_and_trunc(train_sentences, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
        "val_pad_trunc_seq = seq_pad_and_trunc(test_sentences, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
        "\n",
        "print(f\"Padded and truncated training sequences have shape: {train_pad_trunc_seq.shape}\\n\")\n",
        "print(f\"Padded and truncated validation sequences have shape: {val_pad_trunc_seq.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OR3wfthriCnN"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_labels)\n",
        "val_labels = np.array(test_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j0j16iy7iI-m"
      },
      "source": [
        "# Using pre-defined Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "tUHybcFMiE0d"
      },
      "outputs": [],
      "source": [
        "# Define path to file containing the embeddings\n",
        "GLOVE_FILE = 'glove.6B.100d.txt'\n",
        "\n",
        "# Initialize an empty embeddings index dictionary\n",
        "GLOVE_EMBEDDINGS = {}\n",
        "\n",
        "# Read file and fill GLOVE_EMBEDDINGS with its contents\n",
        "with open(GLOVE_FILE) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        GLOVE_EMBEDDINGS[word] = coefs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ldaN0eawl5v5"
      },
      "source": [
        "# Represent the words in your vocabulary using the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Rokt-fwRl8NB"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty numpy array with the appropriate size\n",
        "EMBEDDINGS_MATRIX = np.zeros((VOCAB_SIZE+1, EMBEDDING_DIM))\n",
        "\n",
        "# Iterate all of the words in the vocabulary and if the vector representation for \n",
        "# each word exists within GloVe's representations, save it in the EMBEDDINGS_MATRIX array\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = GLOVE_EMBEDDINGS.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        EMBEDDINGS_MATRIX[i] = embedding_vector"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HZjjYxbzl8ga"
      },
      "source": [
        "# Define a model that does not overfit"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QPn--pNsDhEv"
      },
      "source": [
        "Model with 0.001 learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HAWbMeF-mBg5"
      },
      "outputs": [],
      "source": [
        "# def create_model(vocab_size, embedding_dim, maxlen, embeddings_matrix):\n",
        "#     model = tf.keras.Sequential([ \n",
        "#         # This is how you need to set the Embedding layer when using pre-trained embeddings\n",
        "#         tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=maxlen, weights=[embeddings_matrix], trainable=False),\n",
        "#         tf.keras.layers.Conv1D(32, 5, activation='relu'),\n",
        "#         tf.keras.layers.GlobalMaxPooling1D(),\n",
        "#         tf.keras.layers.Dropout(0.2),\n",
        "#         tf.keras.layers.Dense(32, activation='relu'),\n",
        "#         tf.keras.layers.Dense(3, activation='softmax'),\n",
        "#     ])\n",
        "    \n",
        "#     model.compile(loss='sparse_categorical_crossentropy',\n",
        "#                   optimizer='adam',\n",
        "#                   metrics=['accuracy']) \n",
        "#     return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_iIk4pY1DcZd"
      },
      "source": [
        "Model with 0.002 learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eLywL_aR9KSf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def create_model(vocab_size, embedding_dim, maxlen, embeddings_matrix):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=maxlen, weights=[embeddings_matrix], trainable=False),\n",
        "        tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(3, activation='softmax'),\n",
        "    ])\n",
        "    optimizer = optimizers.Adam(learning_rate = 0.002)\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy']) \n",
        "    return model\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ewJcvwnoIwCh"
      },
      "source": [
        "Model with 0.0025 learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "BB31XCglDbsW"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras import optimizers\n",
        "\n",
        "# def create_model(vocab_size, embedding_dim, maxlen, embeddings_matrix):\n",
        "#     model = tf.keras.Sequential([\n",
        "#         tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=maxlen, weights=[embeddings_matrix], trainable=False),\n",
        "#         tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "#         tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "#         tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
        "#         tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "#         tf.keras.layers.Dense(64, activation='relu'),\n",
        "#         tf.keras.layers.Dropout(0.2),\n",
        "#         tf.keras.layers.Dense(3, activation='softmax'),\n",
        "#     ])\n",
        "#     optimizer = optimizers.Adam(learning_rate = 0.0025)\n",
        "#     model.compile(loss='sparse_categorical_crossentropy',\n",
        "#                   optimizer=optimizer,\n",
        "#                   metrics=['accuracy']) \n",
        "#     return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ePMfJY5UKPB4"
      },
      "outputs": [],
      "source": [
        "model = create_model(VOCAB_SIZE, EMBEDDING_DIM, MAXLEN, EMBEDDINGS_MATRIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZnbOCPTQ_QK",
        "outputId": "451aa618-9688-49c8-8131-bc5d32431eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 16, 100)           367000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 14, 64)            19264     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 7, 64)            0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 7, 128)           49920     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               31104     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 471,643\n",
            "Trainable params: 104,643\n",
            "Non-trainable params: 367,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArRf_nFcmEjZ",
        "outputId": "b1668d0a-bda0-4afe-97b2-88b21f8f27db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "86/86 [==============================] - 30s 42ms/step - loss: 0.9153 - accuracy: 0.5778 - val_loss: 0.7652 - val_accuracy: 0.6733\n",
            "Epoch 2/200\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7061 - accuracy: 0.7107 - val_loss: 0.6655 - val_accuracy: 0.7360\n",
            "Epoch 3/200\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.5716 - accuracy: 0.7794 - val_loss: 0.6788 - val_accuracy: 0.7426\n",
            "Epoch 4/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.5143 - accuracy: 0.7981 - val_loss: 0.7477 - val_accuracy: 0.7129\n",
            "Epoch 5/200\n",
            "86/86 [==============================] - 1s 17ms/step - loss: 0.3905 - accuracy: 0.8550 - val_loss: 0.7317 - val_accuracy: 0.7393\n",
            "Epoch 6/200\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.3174 - accuracy: 0.8814 - val_loss: 0.7990 - val_accuracy: 0.7360\n",
            "Epoch 7/200\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.2657 - accuracy: 0.9053 - val_loss: 0.9699 - val_accuracy: 0.6700\n",
            "Epoch 8/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.2308 - accuracy: 0.9178 - val_loss: 0.8533 - val_accuracy: 0.7162\n",
            "Epoch 9/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.1645 - accuracy: 0.9460 - val_loss: 0.9365 - val_accuracy: 0.7558\n",
            "Epoch 10/200\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.1286 - accuracy: 0.9552 - val_loss: 1.1006 - val_accuracy: 0.7360\n",
            "Epoch 11/200\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.1095 - accuracy: 0.9607 - val_loss: 1.1670 - val_accuracy: 0.7525\n",
            "Epoch 12/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.0719 - accuracy: 0.9761 - val_loss: 1.5626 - val_accuracy: 0.7228\n",
            "Epoch 13/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.0820 - accuracy: 0.9732 - val_loss: 1.3340 - val_accuracy: 0.7261\n",
            "Epoch 14/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.0685 - accuracy: 0.9776 - val_loss: 1.4021 - val_accuracy: 0.7096\n",
            "Epoch 15/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.0980 - accuracy: 0.9622 - val_loss: 1.6196 - val_accuracy: 0.6667\n",
            "Epoch 16/200\n",
            "86/86 [==============================] - 1s 17ms/step - loss: 0.0812 - accuracy: 0.9739 - val_loss: 1.2375 - val_accuracy: 0.7261\n",
            "Epoch 17/200\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.0598 - accuracy: 0.9809 - val_loss: 1.4961 - val_accuracy: 0.7228\n",
            "Epoch 18/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.0409 - accuracy: 0.9835 - val_loss: 1.7980 - val_accuracy: 0.6898\n",
            "Epoch 19/200\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.0679 - accuracy: 0.9739 - val_loss: 2.0859 - val_accuracy: 0.6964\n",
            "Epoch 20/200\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.0585 - accuracy: 0.9772 - val_loss: 1.6785 - val_accuracy: 0.7063\n",
            "Epoch 21/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.0367 - accuracy: 0.9864 - val_loss: 2.1992 - val_accuracy: 0.7195\n",
            "Epoch 22/200\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.2360 - accuracy: 0.9258 - val_loss: 1.3022 - val_accuracy: 0.7294\n",
            "Epoch 23/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0611 - accuracy: 0.9791 - val_loss: 1.2780 - val_accuracy: 0.7657\n",
            "Epoch 24/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0294 - accuracy: 0.9879 - val_loss: 1.5612 - val_accuracy: 0.7162\n",
            "Epoch 25/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 1.5502 - val_accuracy: 0.7426\n",
            "Epoch 26/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0219 - accuracy: 0.9908 - val_loss: 1.5659 - val_accuracy: 0.7261\n",
            "Epoch 27/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 1.6669 - val_accuracy: 0.7294\n",
            "Epoch 28/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1328 - accuracy: 0.9552 - val_loss: 1.3879 - val_accuracy: 0.7327\n",
            "Epoch 29/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0414 - accuracy: 0.9842 - val_loss: 1.6204 - val_accuracy: 0.7228\n",
            "Epoch 30/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0186 - accuracy: 0.9916 - val_loss: 1.9077 - val_accuracy: 0.7129\n",
            "Epoch 31/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0113 - accuracy: 0.9949 - val_loss: 1.7778 - val_accuracy: 0.7525\n",
            "Epoch 32/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0090 - accuracy: 0.9949 - val_loss: 1.9586 - val_accuracy: 0.7294\n",
            "Epoch 33/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0084 - accuracy: 0.9945 - val_loss: 1.8677 - val_accuracy: 0.7591\n",
            "Epoch 34/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0089 - accuracy: 0.9945 - val_loss: 1.9444 - val_accuracy: 0.7426\n",
            "Epoch 35/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0086 - accuracy: 0.9952 - val_loss: 1.8710 - val_accuracy: 0.7558\n",
            "Epoch 36/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 0.9945 - val_loss: 2.0575 - val_accuracy: 0.7294\n",
            "Epoch 37/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 2.0232 - val_accuracy: 0.7525\n",
            "Epoch 38/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0078 - accuracy: 0.9960 - val_loss: 2.0645 - val_accuracy: 0.7459\n",
            "Epoch 39/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0074 - accuracy: 0.9956 - val_loss: 2.0226 - val_accuracy: 0.7525\n",
            "Epoch 40/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0074 - accuracy: 0.9956 - val_loss: 2.0286 - val_accuracy: 0.7492\n",
            "Epoch 41/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9952 - val_loss: 2.0907 - val_accuracy: 0.7492\n",
            "Epoch 42/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 0.9949 - val_loss: 2.0673 - val_accuracy: 0.7525\n",
            "Epoch 43/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0072 - accuracy: 0.9960 - val_loss: 2.1137 - val_accuracy: 0.7492\n",
            "Epoch 44/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0071 - accuracy: 0.9956 - val_loss: 2.1087 - val_accuracy: 0.7525\n",
            "Epoch 45/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9945 - val_loss: 2.1923 - val_accuracy: 0.7459\n",
            "Epoch 46/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9956 - val_loss: 2.1410 - val_accuracy: 0.7492\n",
            "Epoch 47/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0072 - accuracy: 0.9952 - val_loss: 2.2002 - val_accuracy: 0.7426\n",
            "Epoch 48/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0070 - accuracy: 0.9956 - val_loss: 2.1350 - val_accuracy: 0.7525\n",
            "Epoch 49/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 0.9952 - val_loss: 2.1967 - val_accuracy: 0.7492\n",
            "Epoch 50/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 2.1628 - val_accuracy: 0.7558\n",
            "Epoch 51/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 2.1748 - val_accuracy: 0.7492\n",
            "Epoch 52/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9971 - val_loss: 2.2492 - val_accuracy: 0.7492\n",
            "Epoch 53/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 2.2735 - val_accuracy: 0.7525\n",
            "Epoch 54/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.2700 - val_accuracy: 0.7492\n",
            "Epoch 55/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9952 - val_loss: 2.2763 - val_accuracy: 0.7525\n",
            "Epoch 56/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9952 - val_loss: 2.3049 - val_accuracy: 0.7426\n",
            "Epoch 57/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0071 - accuracy: 0.9952 - val_loss: 2.3169 - val_accuracy: 0.7459\n",
            "Epoch 58/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0060 - accuracy: 0.9967 - val_loss: 2.3080 - val_accuracy: 0.7558\n",
            "Epoch 59/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9960 - val_loss: 2.3529 - val_accuracy: 0.7492\n",
            "Epoch 60/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0070 - accuracy: 0.9956 - val_loss: 2.3838 - val_accuracy: 0.7459\n",
            "Epoch 61/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9967 - val_loss: 2.2852 - val_accuracy: 0.7525\n",
            "Epoch 62/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 2.3467 - val_accuracy: 0.7492\n",
            "Epoch 63/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0066 - accuracy: 0.9960 - val_loss: 2.3791 - val_accuracy: 0.7492\n",
            "Epoch 64/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0068 - accuracy: 0.9949 - val_loss: 2.4094 - val_accuracy: 0.7459\n",
            "Epoch 65/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.4586 - val_accuracy: 0.7492\n",
            "Epoch 66/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 2.4597 - val_accuracy: 0.7492\n",
            "Epoch 67/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 2.5012 - val_accuracy: 0.7492\n",
            "Epoch 68/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.4879 - val_accuracy: 0.7525\n",
            "Epoch 69/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9960 - val_loss: 2.5484 - val_accuracy: 0.7492\n",
            "Epoch 70/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.5218 - val_accuracy: 0.7492\n",
            "Epoch 71/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 2.7520 - val_accuracy: 0.7261\n",
            "Epoch 72/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.2087 - accuracy: 0.9343 - val_loss: 0.7916 - val_accuracy: 0.7096\n",
            "Epoch 73/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.2946 - accuracy: 0.8939 - val_loss: 1.0514 - val_accuracy: 0.7162\n",
            "Epoch 74/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.1054 - accuracy: 0.9622 - val_loss: 1.4768 - val_accuracy: 0.7063\n",
            "Epoch 75/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0682 - accuracy: 0.9754 - val_loss: 1.4338 - val_accuracy: 0.6865\n",
            "Epoch 76/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0525 - accuracy: 0.9805 - val_loss: 1.4409 - val_accuracy: 0.7162\n",
            "Epoch 77/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0627 - accuracy: 0.9794 - val_loss: 1.3348 - val_accuracy: 0.7459\n",
            "Epoch 78/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0432 - accuracy: 0.9849 - val_loss: 1.5509 - val_accuracy: 0.7327\n",
            "Epoch 79/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0381 - accuracy: 0.9879 - val_loss: 1.6089 - val_accuracy: 0.7426\n",
            "Epoch 80/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0259 - accuracy: 0.9897 - val_loss: 1.8458 - val_accuracy: 0.7162\n",
            "Epoch 81/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0283 - accuracy: 0.9890 - val_loss: 1.7855 - val_accuracy: 0.7228\n",
            "Epoch 82/200\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.0229 - accuracy: 0.9908 - val_loss: 1.8684 - val_accuracy: 0.7393\n",
            "Epoch 83/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0139 - accuracy: 0.9930 - val_loss: 1.7657 - val_accuracy: 0.7690\n",
            "Epoch 84/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0138 - accuracy: 0.9934 - val_loss: 1.9504 - val_accuracy: 0.7294\n",
            "Epoch 85/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 1.8621 - val_accuracy: 0.7492\n",
            "Epoch 86/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0110 - accuracy: 0.9938 - val_loss: 1.9372 - val_accuracy: 0.7459\n",
            "Epoch 87/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0078 - accuracy: 0.9956 - val_loss: 2.0564 - val_accuracy: 0.7426\n",
            "Epoch 88/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.0300 - val_accuracy: 0.7426\n",
            "Epoch 89/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9960 - val_loss: 2.0864 - val_accuracy: 0.7459\n",
            "Epoch 90/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0072 - accuracy: 0.9952 - val_loss: 2.1377 - val_accuracy: 0.7426\n",
            "Epoch 91/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0069 - accuracy: 0.9956 - val_loss: 2.1611 - val_accuracy: 0.7426\n",
            "Epoch 92/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0069 - accuracy: 0.9952 - val_loss: 2.1679 - val_accuracy: 0.7459\n",
            "Epoch 93/200\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0067 - accuracy: 0.9967 - val_loss: 2.1493 - val_accuracy: 0.7459\n",
            "Epoch 94/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0065 - accuracy: 0.9952 - val_loss: 2.2143 - val_accuracy: 0.7459\n",
            "Epoch 95/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0071 - accuracy: 0.9949 - val_loss: 2.2064 - val_accuracy: 0.7492\n",
            "Epoch 96/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9949 - val_loss: 2.2061 - val_accuracy: 0.7492\n",
            "Epoch 97/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9960 - val_loss: 2.2693 - val_accuracy: 0.7459\n",
            "Epoch 98/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9952 - val_loss: 2.2773 - val_accuracy: 0.7459\n",
            "Epoch 99/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9967 - val_loss: 2.2821 - val_accuracy: 0.7492\n",
            "Epoch 100/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9956 - val_loss: 2.3415 - val_accuracy: 0.7492\n",
            "Epoch 101/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9956 - val_loss: 2.3463 - val_accuracy: 0.7459\n",
            "Epoch 102/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9956 - val_loss: 2.3180 - val_accuracy: 0.7492\n",
            "Epoch 103/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9956 - val_loss: 2.3442 - val_accuracy: 0.7492\n",
            "Epoch 104/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9963 - val_loss: 2.3528 - val_accuracy: 0.7492\n",
            "Epoch 105/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.3892 - val_accuracy: 0.7492\n",
            "Epoch 106/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0074 - accuracy: 0.9956 - val_loss: 2.1702 - val_accuracy: 0.7492\n",
            "Epoch 107/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0075 - accuracy: 0.9952 - val_loss: 2.2090 - val_accuracy: 0.7393\n",
            "Epoch 108/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0071 - accuracy: 0.9960 - val_loss: 2.3843 - val_accuracy: 0.7492\n",
            "Epoch 109/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9960 - val_loss: 2.4531 - val_accuracy: 0.7426\n",
            "Epoch 110/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0061 - accuracy: 0.9967 - val_loss: 2.4928 - val_accuracy: 0.7393\n",
            "Epoch 111/200\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0069 - accuracy: 0.9956 - val_loss: 2.5584 - val_accuracy: 0.7393\n",
            "Epoch 112/200\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.0070 - accuracy: 0.9960 - val_loss: 2.5213 - val_accuracy: 0.7360\n",
            "Epoch 113/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9956 - val_loss: 2.5172 - val_accuracy: 0.7360\n",
            "Epoch 114/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9952 - val_loss: 2.5283 - val_accuracy: 0.7459\n",
            "Epoch 115/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9952 - val_loss: 2.5027 - val_accuracy: 0.7426\n",
            "Epoch 116/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 2.5579 - val_accuracy: 0.7525\n",
            "Epoch 117/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1759 - accuracy: 0.9438 - val_loss: 1.2199 - val_accuracy: 0.6997\n",
            "Epoch 118/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.2353 - accuracy: 0.9104 - val_loss: 1.3332 - val_accuracy: 0.7195\n",
            "Epoch 119/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0866 - accuracy: 0.9710 - val_loss: 1.3786 - val_accuracy: 0.7195\n",
            "Epoch 120/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 1.6067 - val_accuracy: 0.7063\n",
            "Epoch 121/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 1.6417 - val_accuracy: 0.7162\n",
            "Epoch 122/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0252 - accuracy: 0.9897 - val_loss: 2.1231 - val_accuracy: 0.6898\n",
            "Epoch 123/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0550 - accuracy: 0.9787 - val_loss: 1.9324 - val_accuracy: 0.7063\n",
            "Epoch 124/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0609 - accuracy: 0.9769 - val_loss: 1.4523 - val_accuracy: 0.7096\n",
            "Epoch 125/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9927 - val_loss: 1.6282 - val_accuracy: 0.7162\n",
            "Epoch 126/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0087 - accuracy: 0.9949 - val_loss: 1.7230 - val_accuracy: 0.7327\n",
            "Epoch 127/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0071 - accuracy: 0.9952 - val_loss: 1.8199 - val_accuracy: 0.7327\n",
            "Epoch 128/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0071 - accuracy: 0.9941 - val_loss: 1.8519 - val_accuracy: 0.7360\n",
            "Epoch 129/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9963 - val_loss: 1.8961 - val_accuracy: 0.7393\n",
            "Epoch 130/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 1.9227 - val_accuracy: 0.7393\n",
            "Epoch 131/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9952 - val_loss: 1.9528 - val_accuracy: 0.7360\n",
            "Epoch 132/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9952 - val_loss: 1.9901 - val_accuracy: 0.7393\n",
            "Epoch 133/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0070 - accuracy: 0.9949 - val_loss: 2.0178 - val_accuracy: 0.7360\n",
            "Epoch 134/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 0.9956 - val_loss: 2.0244 - val_accuracy: 0.7327\n",
            "Epoch 135/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0064 - accuracy: 0.9952 - val_loss: 2.0327 - val_accuracy: 0.7393\n",
            "Epoch 136/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0066 - accuracy: 0.9949 - val_loss: 2.0615 - val_accuracy: 0.7360\n",
            "Epoch 137/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.0842 - val_accuracy: 0.7360\n",
            "Epoch 138/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9952 - val_loss: 2.0880 - val_accuracy: 0.7360\n",
            "Epoch 139/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.1492 - val_accuracy: 0.7360\n",
            "Epoch 140/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 2.1122 - val_accuracy: 0.7360\n",
            "Epoch 141/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9960 - val_loss: 2.1015 - val_accuracy: 0.7393\n",
            "Epoch 142/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.1455 - val_accuracy: 0.7360\n",
            "Epoch 143/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 0.9956 - val_loss: 2.1049 - val_accuracy: 0.7327\n",
            "Epoch 144/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 0.9956 - val_loss: 2.1371 - val_accuracy: 0.7360\n",
            "Epoch 145/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9956 - val_loss: 2.1480 - val_accuracy: 0.7393\n",
            "Epoch 146/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.1499 - val_accuracy: 0.7393\n",
            "Epoch 147/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 2.1616 - val_accuracy: 0.7459\n",
            "Epoch 148/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.1753 - val_accuracy: 0.7426\n",
            "Epoch 149/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0066 - accuracy: 0.9960 - val_loss: 2.1953 - val_accuracy: 0.7426\n",
            "Epoch 150/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0063 - accuracy: 0.9952 - val_loss: 2.2210 - val_accuracy: 0.7393\n",
            "Epoch 151/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0070 - accuracy: 0.9952 - val_loss: 2.2557 - val_accuracy: 0.7459\n",
            "Epoch 152/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9952 - val_loss: 2.3026 - val_accuracy: 0.7492\n",
            "Epoch 153/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 2.2525 - val_accuracy: 0.7459\n",
            "Epoch 154/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9952 - val_loss: 2.3389 - val_accuracy: 0.7525\n",
            "Epoch 155/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9963 - val_loss: 2.3509 - val_accuracy: 0.7492\n",
            "Epoch 156/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9952 - val_loss: 2.3489 - val_accuracy: 0.7492\n",
            "Epoch 157/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9952 - val_loss: 2.3466 - val_accuracy: 0.7492\n",
            "Epoch 158/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 2.3547 - val_accuracy: 0.7492\n",
            "Epoch 159/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9949 - val_loss: 2.3390 - val_accuracy: 0.7525\n",
            "Epoch 160/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 2.3561 - val_accuracy: 0.7459\n",
            "Epoch 161/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 2.3484 - val_accuracy: 0.7492\n",
            "Epoch 162/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0057 - accuracy: 0.9960 - val_loss: 2.4017 - val_accuracy: 0.7459\n",
            "Epoch 163/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9956 - val_loss: 2.4466 - val_accuracy: 0.7492\n",
            "Epoch 164/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0067 - accuracy: 0.9960 - val_loss: 2.4801 - val_accuracy: 0.7525\n",
            "Epoch 165/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0061 - accuracy: 0.9963 - val_loss: 2.3979 - val_accuracy: 0.7525\n",
            "Epoch 166/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0064 - accuracy: 0.9963 - val_loss: 2.3498 - val_accuracy: 0.7459\n",
            "Epoch 167/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9956 - val_loss: 2.4656 - val_accuracy: 0.7492\n",
            "Epoch 168/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 0.9960 - val_loss: 2.4767 - val_accuracy: 0.7525\n",
            "Epoch 169/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 2.0058 - val_accuracy: 0.7327\n",
            "Epoch 170/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.2577 - accuracy: 0.9071 - val_loss: 1.0392 - val_accuracy: 0.7393\n",
            "Epoch 171/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1194 - accuracy: 0.9574 - val_loss: 1.2591 - val_accuracy: 0.7360\n",
            "Epoch 172/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0694 - accuracy: 0.9776 - val_loss: 1.3256 - val_accuracy: 0.7558\n",
            "Epoch 173/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0345 - accuracy: 0.9868 - val_loss: 1.5888 - val_accuracy: 0.7426\n",
            "Epoch 174/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 1.6623 - val_accuracy: 0.7690\n",
            "Epoch 175/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 1.5991 - val_accuracy: 0.7558\n",
            "Epoch 176/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0112 - accuracy: 0.9952 - val_loss: 1.7243 - val_accuracy: 0.7657\n",
            "Epoch 177/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0075 - accuracy: 0.9956 - val_loss: 1.7657 - val_accuracy: 0.7591\n",
            "Epoch 178/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 1.8050 - val_accuracy: 0.7657\n",
            "Epoch 179/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0067 - accuracy: 0.9963 - val_loss: 1.8444 - val_accuracy: 0.7657\n",
            "Epoch 180/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0067 - accuracy: 0.9960 - val_loss: 1.8750 - val_accuracy: 0.7624\n",
            "Epoch 181/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 1.8947 - val_accuracy: 0.7624\n",
            "Epoch 182/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9963 - val_loss: 1.9361 - val_accuracy: 0.7591\n",
            "Epoch 183/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 1.9545 - val_accuracy: 0.7657\n",
            "Epoch 184/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 1.9642 - val_accuracy: 0.7657\n",
            "Epoch 185/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 1.9852 - val_accuracy: 0.7690\n",
            "Epoch 186/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9960 - val_loss: 1.9850 - val_accuracy: 0.7525\n",
            "Epoch 187/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9956 - val_loss: 1.9965 - val_accuracy: 0.7591\n",
            "Epoch 188/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 2.0135 - val_accuracy: 0.7591\n",
            "Epoch 189/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9956 - val_loss: 2.0289 - val_accuracy: 0.7690\n",
            "Epoch 190/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 2.0433 - val_accuracy: 0.7624\n",
            "Epoch 191/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9956 - val_loss: 2.0601 - val_accuracy: 0.7591\n",
            "Epoch 192/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.0815 - val_accuracy: 0.7657\n",
            "Epoch 193/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.0866 - val_accuracy: 0.7558\n",
            "Epoch 194/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 2.1022 - val_accuracy: 0.7690\n",
            "Epoch 195/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0064 - accuracy: 0.9963 - val_loss: 2.1165 - val_accuracy: 0.7657\n",
            "Epoch 196/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0064 - accuracy: 0.9952 - val_loss: 2.1186 - val_accuracy: 0.7624\n",
            "Epoch 197/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.1207 - val_accuracy: 0.7558\n",
            "Epoch 198/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9956 - val_loss: 2.1453 - val_accuracy: 0.7591\n",
            "Epoch 199/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.1339 - val_accuracy: 0.7723\n",
            "Epoch 200/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0060 - accuracy: 0.9963 - val_loss: 2.1423 - val_accuracy: 0.7657\n"
          ]
        }
      ],
      "source": [
        "# Train the model and save the training history\n",
        "history = model.fit(train_pad_trunc_seq, train_labels, epochs=200, validation_data=(val_pad_trunc_seq, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icfjRpZh0Pao",
        "outputId": "7e5d21f9-e9aa-45b6-a2ff-9c582c86641a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 4ms/step\n",
            "Precision:  0.7647184073246034\n",
            "Recall:  0.7656765676567657\n",
            "F1-score:  0.7649426279837286\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Make predictions on the validation set\n",
        "val_predictions = model.predict(val_pad_trunc_seq)\n",
        "val_predicted_labels = np.argmax(val_predictions, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(val_labels, val_predicted_labels, average='weighted')\n",
        "recall = recall_score(val_labels, val_predicted_labels, average='weighted')\n",
        "f1 = f1_score(val_labels, val_predicted_labels, average='weighted')\n",
        "\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1-score: \", f1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8LTrwH3183K"
      },
      "source": [
        "Based on the evaluation metrics, our model performs relatively well with relatively high values of precision, recall, and F1-score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ3kZzdTxbfe"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unF3XUmIzde8",
        "outputId": "d8abbf99-b285-4ccc-aef3-00e198d8d4a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "Text: Smart , but can't teach\n",
            "Predicted Sentiment: Neutral\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have trained the model and obtained the history\n",
        "\n",
        "# Random text for prediction\n",
        "random_text = \"Smart , but can't teach\"\n",
        "\n",
        "# Tokenize the random text\n",
        "random_text_sequence = tokenizer.texts_to_sequences([random_text])\n",
        "\n",
        "# Pad and truncate the sequence\n",
        "random_text_sequence = pad_sequences(random_text_sequence, maxlen=MAXLEN, padding=PADDING, truncating=TRUNCATING)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(random_text_sequence)[0]\n",
        "\n",
        "# Convert prediction to sentiment label\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Map sentiment label to sentiment interpretation\n",
        "sentiment = \"Positive\" if predicted_label == 2 else \"Neutral\" if predicted_label == 1 else \"Negative\"\n",
        "\n",
        "# Print the prediction result\n",
        "print(f\"Text: {random_text}\")\n",
        "print(f\"Predicted Sentiment: {sentiment}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJW1tCA4x4mA",
        "outputId": "14b1d92c-1b3a-47ef-eb8b-bb07e0c6dfe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[152,  61,  62,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0]], dtype=int32)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random text for prediction\n",
        "random_text = \"Bad at teaching\"\n",
        "\n",
        "# Tokenize the random text\n",
        "random_text_sequence = tokenizer.texts_to_sequences([random_text])\n",
        "random_text_sequence = pad_sequences(random_text_sequence, maxlen=MAXLEN, padding=PADDING, truncating=TRUNCATING)\n",
        "random_text_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlpY4lfA0Amw",
        "outputId": "a28173e9-0f8b-4c30-e8ec-70010290788b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict(random_text_sequence)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "7jzcy6_k0IcT"
      },
      "outputs": [],
      "source": [
        "prediction\n",
        "# Convert prediction to sentiment label\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Map sentiment label to sentiment interpretation\n",
        "sentiment = \"Positive\" if predicted_label == 2 else \"Neutral\" if predicted_label == 1 else \"Negative\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nPuumBWW0J4Z",
        "outputId": "15dd4c6d-4879-4082-9ad6-0cf101e1f7a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qG4PcqhVyFmy"
      },
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "K4K14Xlt4LJX"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "vv76Slt70Qpu"
      },
      "outputs": [],
      "source": [
        "# tf.saved_model.save(model, 'saved_model')\n",
        "# model.save('model.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "nR-XMfSa3-pW"
      },
      "outputs": [],
      "source": [
        "# converter = tf.lite.TFLiteConverter.from_saved_model('saved_model')\n",
        "# tflite_model = converter.convert()\n",
        "# with open('model.tflite', 'wb') as f:\n",
        "#     f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "XJPg4SNldKo-",
        "XBbquN0qf6Og",
        "Hkha78ZLhD8n",
        "j0j16iy7iI-m",
        "ldaN0eawl5v5",
        "HZjjYxbzl8ga"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
