{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import linregress"
      ],
      "metadata": {
        "id": "_qfzq2wDZmkx"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('ReviewsEN.csv')"
      ],
      "metadata": {
        "id": "Vd4os3NhZp5l"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-1 :\", df['sentiment'].value_counts()[-1])\n",
        "print(\"0 :\", df['sentiment'].value_counts()[0])\n",
        "print(\"1 :\", df['sentiment'].value_counts()[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uQq0VQTZ9iF",
        "outputId": "60972175-f2f7-4c5f-f923-94ecf5e3c5ba"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1 : 870\n",
            "0 : 639\n",
            "1 : 1518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace values in pandas DataFrame.\n",
        "df['sentiment'] = df['sentiment'].replace([1], 2)\n",
        "df['sentiment'] = df['sentiment'].replace([0], 1)\n",
        "df['sentiment'] = df['sentiment'].replace([-1], 0)"
      ],
      "metadata": {
        "id": "DsSXQdDXZ-0R"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case Folding"
      ],
      "metadata": {
        "id": "VeUKsk6Xc96m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply lower function\n",
        "df['reviews'] = df['reviews'].apply(str.lower)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "RayqsORYaBXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17d0183-69b7-4caf-ee26-0acf9f639464"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      sentiment                                            reviews\n",
            "0             1  teacher are punctual but they should also give...\n",
            "1             2                                               good\n",
            "2             2  excellent lectures are delivered by teachers a...\n",
            "3             2  teachers give us all the information required ...\n",
            "4             2                                                yes\n",
            "...         ...                                                ...\n",
            "3022          2        lecturers provide clear enough explanations\n",
            "3023          2            lecturer's assessment is very objective\n",
            "3024          0              lecturers give very good explanations\n",
            "3025          0        lecturers often provoke discussion in class\n",
            "3026          2         lecturers provide material in a boring way\n",
            "\n",
            "[3027 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper Parameter"
      ],
      "metadata": {
        "id": "GPHtwv2EdE9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Variables\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "MAXLEN = 16\n",
        "TRUNCATING = 'post'\n",
        "PADDING = 'post'\n",
        "OOV_TOKEN = \"<OOV>\"\n",
        "MAX_EXAMPLES = len(df)\n",
        "TRAINING_SPLIT = 0.8"
      ],
      "metadata": {
        "id": "xSDvqvHSeqFr"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Punctuation"
      ],
      "metadata": {
        "id": "yuvN6YvqdOr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Remove punctuation marks\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text_without_punctuation = text.translate(translator)\n",
        "    return text_without_punctuation"
      ],
      "metadata": {
        "id": "jlE8pTQ8c6e_"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "removedPunctuation_text = []\n",
        "for i in range(len(df)):\n",
        "  removedPunctuation_text.append(remove_punctuation(df['reviews'][i]))\n",
        "\n",
        "df['reviews'] = removedPunctuation_text\n",
        "df['reviews'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4Se9P5ddTtG",
        "outputId": "fadb864a-c2d0-4243-f2cc-a4001c75e48d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['teacher are punctual but they should also give us the some practical knowledge other than theortical',\n",
              "       'good',\n",
              "       'excellent lectures are delivered by teachers and all teachers are very punctual',\n",
              "       ..., 'lecturers give very good explanations',\n",
              "       'lecturers often provoke discussion in class',\n",
              "       'lecturers provide material in a boring way'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatizing"
      ],
      "metadata": {
        "id": "wuUyzP-PdmZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = []\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    for token in tokens:\n",
        "        lemma = lemmatizer.lemmatize(token)\n",
        "        lemmatized_words.append(lemma)\n",
        "    lemmatized_text = ' '.join(lemmatized_words)\n",
        "    return lemmatized_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvF7m92Li9iX",
        "outputId": "f2fac824-ec16-4682-df65-204b6bac7153"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp =  []\n",
        "for i in range(len(df)):\n",
        "  temp.append(lemmatize_text(df['reviews'][i]))\n",
        "df['reviews'] = temp"
      ],
      "metadata": {
        "id": "LzeSycQJjF83"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Numbers"
      ],
      "metadata": {
        "id": "z_Sk8mp7jdzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_numbers(text):\n",
        "    cleaned_text = re.sub(r'\\d+', '', text)\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "gsE6EaxtjiV_"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['reviews'] = df['reviews'].apply(remove_numbers)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Wsfvp3VOj7Vm",
        "outputId": "08d128ca-4086-423a-922a-4f151a20a9e0"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      sentiment                                            reviews\n",
              "0             1  teacher are punctual but they should also give...\n",
              "1             2                                               good\n",
              "2             2  excellent lecture are delivered by teacher and...\n",
              "3             2  teacher give u all the information required to...\n",
              "4             2                                                yes\n",
              "...         ...                                                ...\n",
              "3022          2          lecturer provide clear enough explanation\n",
              "3023          2              lecturer assessment is very objective\n",
              "3024          0                lecturer give very good explanation\n",
              "3025          0         lecturer often provoke discussion in class\n",
              "3026          2          lecturer provide material in a boring way\n",
              "\n",
              "[3027 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-619ef8da-48b2-425e-91e2-9ac321559179\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>teacher are punctual but they should also give...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>excellent lecture are delivered by teacher and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>teacher give u all the information required to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3022</th>\n",
              "      <td>2</td>\n",
              "      <td>lecturer provide clear enough explanation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3023</th>\n",
              "      <td>2</td>\n",
              "      <td>lecturer assessment is very objective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>0</td>\n",
              "      <td>lecturer give very good explanation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3025</th>\n",
              "      <td>0</td>\n",
              "      <td>lecturer often provoke discussion in class</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3026</th>\n",
              "      <td>2</td>\n",
              "      <td>lecturer provide material in a boring way</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3027 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-619ef8da-48b2-425e-91e2-9ac321559179')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-619ef8da-48b2-425e-91e2-9ac321559179 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-619ef8da-48b2-425e-91e2-9ac321559179');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Sampling"
      ],
      "metadata": {
        "id": "XJPg4SNldKo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "# Get the indices of the DataFrame\n",
        "indices = df.index.tolist()\n",
        "\n",
        "# Perform random sampling on the indices\n",
        "selected_indices = random.sample(indices, MAX_EXAMPLES)\n",
        "\n",
        "# Select the corresponding sentences and labels based on the sampled indices\n",
        "sentences = df.loc[selected_indices, 'reviews']\n",
        "labels = df.loc[selected_indices, 'sentiment']\n",
        "\n",
        "print(f\"There are {len(sentences)} sentences and {len(labels)} labels after random sampling\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm_QQl4setsh",
        "outputId": "1da9c679-9e72-48c0-bd12-adf099a013ed"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3027 sentences and 3027 labels after random sampling\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_indices)\n",
        "print(len(selected_indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y55xrCToyAD-",
        "outputId": "75deb1ee-9dda-4228-e7db-0acd6fda192b"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2619, 456, 102, 1126, 1003, 914, 571, 3016, 419, 2771, 2233, 356, 2418, 1728, 130, 122, 383, 895, 952, 2069, 2465, 108, 2298, 814, 2932, 2661, 2872, 2232, 1718, 902, 1839, 2413, 1139, 26, 653, 2859, 1731, 1393, 1138, 636, 881, 1378, 418, 379, 1556, 396, 1470, 1408, 2472, 1083, 177, 1881, 2196, 511, 1550, 322, 2261, 1200, 2574, 2533, 1481, 2364, 787, 2885, 284, 187, 2708, 933, 1185, 326, 953, 413, 2982, 2988, 1857, 2603, 1494, 666, 1516, 1455, 858, 2745, 1093, 2874, 2799, 2654, 292, 2495, 2600, 700, 2187, 1002, 669, 1893, 1554, 1105, 2621, 2818, 2281, 899, 2804, 1328, 229, 938, 131, 1292, 1643, 1096, 271, 864, 2323, 1288, 870, 2684, 2044, 1620, 2633, 1879, 585, 1084, 3020, 1010, 2299, 2207, 1076, 2394, 1754, 2390, 1635, 1482, 898, 566, 2087, 2021, 372, 192, 449, 626, 2570, 655, 2787, 1729, 2442, 260, 1576, 1563, 2440, 1917, 2167, 1029, 2266, 47, 2786, 469, 2792, 2199, 1092, 2625, 2989, 3025, 1202, 1780, 647, 1858, 13, 1078, 2050, 731, 2079, 435, 2561, 1222, 2617, 2858, 2494, 3003, 2889, 1531, 661, 2209, 2172, 2, 2453, 1327, 2001, 79, 458, 1486, 1259, 980, 237, 986, 2916, 2971, 350, 1990, 283, 2181, 515, 525, 2702, 1946, 2251, 676, 1085, 2161, 2484, 1733, 867, 2208, 823, 1276, 1634, 2751, 3001, 1529, 1794, 2119, 1849, 495, 1015, 920, 262, 1384, 86, 2409, 2268, 942, 2410, 2997, 29, 290, 2584, 241, 937, 276, 128, 1353, 2795, 2105, 974, 1140, 2740, 1988, 877, 2817, 541, 2338, 2360, 1936, 995, 1937, 1667, 779, 386, 397, 2699, 1765, 1451, 1734, 1683, 1912, 221, 2758, 2676, 2646, 403, 248, 1649, 1389, 447, 1018, 784, 2773, 2974, 1837, 574, 3013, 751, 2785, 1894, 1023, 308, 1815, 2254, 401, 207, 2671, 2214, 60, 382, 968, 681, 1664, 1989, 1971, 875, 1642, 240, 674, 1552, 8, 1599, 1086, 1863, 1168, 1732, 2276, 2711, 1993, 634, 777, 1215, 891, 239, 2372, 2220, 249, 1284, 234, 205, 2392, 1952, 2059, 2175, 644, 232, 2080, 328, 761, 280, 2437, 278, 963, 1653, 491, 2333, 1008, 2371, 2435, 162, 2536, 335, 1717, 2899, 2315, 2141, 1295, 1068, 836, 1286, 977, 1087, 1621, 536, 2643, 1228, 1872, 2679, 297, 38, 1877, 2544, 2306, 409, 300, 2202, 873, 2072, 2723, 542, 1429, 281, 1000, 1513, 1167, 646, 2810, 2225, 1239, 2505, 2166, 32, 2271, 1226, 424, 550, 2977, 472, 438, 2876, 2987, 1115, 1154, 2477, 862, 1404, 833, 2597, 1081, 2070, 2842, 1028, 208, 378, 2598, 2767, 1133, 180, 14, 1366, 535, 2609, 1072, 2848, 1809, 2259, 1751, 2297, 39, 2840, 2744, 610, 2234, 147, 1512, 2385, 2263, 606, 1760, 522, 171, 1262, 1493, 163, 1465, 860, 1022, 421, 1448, 2293, 2733, 2542, 633, 969, 665, 725, 1688, 101, 734, 1360, 1686, 1016, 2870, 652, 442, 1566, 158, 1927, 911, 817, 1885, 1432, 1250, 932, 913, 96, 791, 1632, 1344, 1141, 2962, 1143, 1438, 2086, 1637, 2752, 1356, 113, 2638, 1069, 2991, 2378, 2674, 156, 444, 2443, 1779, 1415, 2960, 1787, 2483, 2094, 473, 1577, 2361, 778, 1043, 181, 1786, 6, 2129, 2205, 807, 1491, 1766, 286, 1352, 1285, 510, 1230, 2077, 1266, 1672, 1336, 1648, 1211, 2270, 521, 785, 1722, 2726, 712, 2331, 1232, 1663, 2244, 1, 1244, 1175, 2590, 2628, 2375, 2820, 1319, 1904, 2611, 1811, 2730, 2093, 1938, 695, 347, 1162, 2111, 1372, 2736, 962, 1271, 2805, 815, 603, 100, 189, 2935, 2825, 298, 1865, 1697, 2357, 796, 1572, 2024, 1636, 999, 604, 22, 436, 1741, 896, 720, 2121, 1902, 2706, 2283, 1020, 497, 1869, 546, 1903, 2826, 2289, 2438, 1299, 1812, 2067, 1747, 2500, 1826, 651, 1944, 1843, 1061, 1012, 1135, 2135, 1984, 979, 1124, 1801, 317, 1170, 960, 1112, 1375, 1309, 2212, 330, 2895, 617, 947, 1568, 625, 876, 263, 1699, 1669, 1355, 2222, 1908, 1703, 255, 847, 1720, 1595, 2705, 80, 2358, 1558, 1953, 24, 1440, 1223, 1597, 1716, 2204, 2236, 903, 1999, 2896, 1117, 1785, 2732, 118, 1592, 1376, 1656, 2823, 1914, 2596, 2936, 110, 1613, 2311, 111, 343, 1755, 555, 1891, 744, 2844, 1065, 2761, 1340, 866, 1862, 1338, 1382, 2965, 2994, 1726, 1033, 2913, 1926, 2841, 2847, 213, 1433, 918, 2941, 164, 127, 2433, 816, 83, 624, 2675, 517, 1939, 468, 2310, 892, 2491, 1049, 1510, 687, 2873, 670, 1274, 2571, 105, 1277, 1537, 1624, 812, 311, 994, 417, 1235, 2807, 168, 1422, 2182, 2900, 1517, 282, 2658, 1397, 51, 2403, 2007, 432, 1775, 1483, 1883, 2850, 1783, 721, 2137, 1106, 2391, 1980, 2334, 1784, 1099, 1320, 1005, 354, 1142, 1846, 998, 2447, 2399, 1377, 117, 2464, 1331, 2367, 1997, 868, 1453, 1058, 1394, 1145, 1131, 41, 2116, 782, 2832, 988, 2585, 2869, 984, 1950, 2010, 1835, 70, 381, 1205, 907, 2380, 996, 1254, 1511, 2486, 2174, 2979, 1742, 1354, 1441, 2863, 1109, 1255, 2877, 944, 494, 788, 2921, 489, 2194, 758, 2754, 886, 1983, 1132, 2148, 1159, 411, 795, 1213, 931, 1478, 2577, 1238, 57, 2376, 518, 1123, 186, 223, 1196, 2339, 2262, 420, 50, 1164, 1922, 1960, 1804, 1395, 755, 210, 1034, 1956, 467, 267, 1641, 2014, 303, 219, 621, 611, 2498, 348, 2968, 485, 1704, 924, 2140, 2398, 1845, 1813, 1217, 1756, 2563, 246, 406, 851, 2917, 2639, 332, 643, 982, 711, 307, 641, 10, 1673, 2186, 1924, 1192, 133, 948, 1180, 1158, 1859, 291, 956, 2177, 810, 2458, 470, 2632, 2604, 1088, 582, 2940, 244, 679, 2838, 1182, 1798, 509, 1919, 1245, 2511, 2634, 2049, 2022, 1793, 329, 2592, 1769, 2291, 1025, 2326, 374, 3000, 84, 1103, 2346, 717, 2568, 2489, 2467, 743, 2938, 2871, 373, 1925, 1425, 2513, 1365, 1315, 428, 658, 1350, 2575, 2029, 2163, 1640, 150, 2531, 360, 2915, 2355, 1324, 474, 1655, 4, 1892, 1692, 222, 768, 2966, 2041, 1810, 211, 2629, 2944, 2672, 1179, 2649, 1985, 2450, 2383, 2837, 648, 1272, 56, 1671, 2610, 2154, 464, 1890, 481, 630, 2091, 1195, 1119, 1701, 1976, 1934, 2286, 1870, 592, 1571, 780, 559, 285, 2272, 2411, 1392, 1094, 2170, 2162, 2855, 2005, 608, 1829, 2127, 991, 706, 680, 1130, 1562, 2423, 772, 2562, 1910, 659, 2865, 2772, 2008, 1428, 2238, 1171, 2235, 478, 1753, 1588, 841, 89, 2695, 1525, 2735, 1444, 2062, 1661, 2703, 790, 1359, 1622, 1680, 1335, 2033, 2321, 1014, 1975, 75, 258, 2624, 1977, 1208, 2231, 1781, 2366, 1790, 1730, 901, 204, 1077, 1864, 935, 31, 1479, 295, 839, 2300, 2363, 1986, 316, 153, 961, 1600, 2656, 693, 2815, 1418, 2851, 1330, 2126, 1744, 672, 1745, 1381, 1759, 2573, 2530, 1954, 2853, 1283, 1471, 1817, 1555, 2462, 2527, 1108, 73, 1264, 140, 480, 2239, 1401, 1886, 588, 465, 2811, 185, 888, 201, 1557, 1297, 2247, 2685, 2000, 908, 340, 1421, 613, 1850, 59, 94, 664, 1630, 114, 600, 2224, 767, 882, 2470, 500, 2543, 843, 2230, 1396, 1623, 368, 2193, 358, 161, 1248, 2783, 783, 1269, 1399, 493, 1019, 2449, 1194, 293, 475, 2242, 1306, 520, 941, 2377, 2114, 19, 1840, 1647, 3008, 2168, 589, 1387, 2441, 323, 151, 904, 707, 1203, 612, 1308, 2277, 1413, 512, 2717, 2990, 618, 407, 2964, 2880, 989, 218, 2191, 781, 2030, 735, 1177, 605, 2564, 2461, 44, 2055, 1348, 2157, 562, 16, 2210, 1771, 2630, 1593, 2138, 2474, 1241, 1526, 1017, 1705, 586, 2026, 2463, 471, 1243, 2729, 2904, 448, 1303, 389, 2478, 513, 1388, 1547, 1476, 2060, 2110, 2274, 2401, 2696, 2762, 198, 2518, 1323, 2400, 632, 1615, 2797, 68, 1186, 747, 1499, 269, 184, 2469, 2934, 1530, 850, 359, 2229, 270, 1610, 1104, 2084, 749, 2878, 1027, 558, 1700, 336, 526, 2579, 2835, 1651, 1814, 1528, 1782, 2295, 1896, 235, 959, 154, 288, 1544, 462, 1761, 1385, 2303, 2731, 813, 2720, 2388, 2556, 2781, 2743, 1619, 808, 28, 2780, 1098, 253, 2226, 754, 2452, 1533, 2381, 2552, 1197, 2017, 1684, 1307, 760, 2764, 2359, 2028, 965, 2308, 1268, 1149, 671, 1249, 453, 1326, 129, 1301, 1687, 950, 1435, 1878, 1329, 2677, 238, 2520, 92, 76, 623, 2689, 2836, 199, 1955, 1100, 277, 2228, 929, 759, 1373, 1521, 1426, 2608, 2946, 2866, 1520, 1488, 2083, 849, 1341, 202, 1707, 2978, 1260, 835, 572, 67, 1882, 2682, 2541, 1940, 910, 483, 742, 203, 1856, 752, 2188, 2133, 1929, 124, 2476, 565, 388, 250, 1743, 1767, 2961, 1357, 434, 1314, 2421, 2860, 43, 103, 1611, 683, 498, 257, 1677, 1156, 2213, 2203, 1567, 2432, 2641, 2969, 2327, 477, 1973, 1585, 302, 1822, 1220, 5, 567, 296, 266, 2307, 2813, 2898, 357, 225, 2789, 52, 1816, 30, 733, 1617, 1614, 487, 2258, 663, 2644, 3015, 543, 107, 259, 1519, 2631, 1995, 2700, 1527, 3012, 975, 2348, 1855, 741, 1051, 2714, 2217, 925, 1031, 1875, 2147, 88, 1489, 1604, 1349, 1067, 2417, 2923, 1317, 63, 2095, 2770, 822, 2659, 1405, 2183, 1004, 1458, 1702, 2886, 165, 2036, 2142, 2198, 134, 2006, 563, 1278, 1296, 1198, 2219, 1601, 2581, 2939, 2901, 2657, 2475, 1725, 1035, 2647, 2986, 1698, 1437, 2707, 1987, 1333, 1129, 1834, 440, 880, 2189, 2660, 2404, 694, 928, 2343, 2179, 2950, 194, 640, 874, 1559, 1362, 1900, 766, 312, 1406, 971, 137, 2218, 174, 190, 884, 197, 1524, 2652, 763, 2098, 2122, 3011, 1201, 1150, 2324, 675, 2481, 1797, 2025, 724, 2954, 2362, 1833, 2131, 2933, 1229, 639, 2456, 212, 1183, 1039, 2857, 1715, 2557, 987, 459, 1603, 2125, 1540, 1696, 1789, 570, 2497, 463, 878, 1148, 1273, 1256, 2370, 1316, 2747, 53, 1247, 1347, 1420, 547, 1935, 369, 2058, 1439, 1823, 2485, 718, 12, 371, 1906, 2246, 1346, 820, 142, 2788, 1590, 62, 1685, 1583, 1570, 770, 859, 1581, 698, 2833, 757, 638, 1933, 2535, 1221, 173, 2287, 318, 2980, 1265, 2578, 1380, 167, 557, 2257, 2801, 2302, 2320, 1844, 905, 848, 1492, 441, 2690, 233, 2912, 1569, 227, 580, 1836, 2757, 1214, 2255, 1079, 2616, 631, 93, 451, 809, 1227, 112, 15, 2984, 1612, 2305, 2347, 523, 2061, 1749, 245, 2032, 2755, 1578, 2090, 264, 1968, 1090, 2746, 1024, 1144, 1368, 2580, 2602, 2539, 2802, 893, 2666, 1901, 159, 2171, 2085, 879, 1174, 828, 1311, 855, 2681, 2332, 829, 42, 1586, 351, 1460, 2942, 1625, 2618, 894, 216, 1675, 2335, 1206, 2897, 1073, 1916, 1861, 635, 1616, 1773, 682, 344, 2794, 1045, 1991, 1445, 3004, 1044, 3017, 715, 719, 1321, 2018, 1800, 2524, 299, 524, 404, 355, 1233, 313, 1342, 1942, 362, 1828, 1011, 2249, 2910, 1819, 919, 2115, 1501, 1974, 1279, 2612, 2537, 2864, 309, 900, 139, 2424, 1450, 1293, 620, 1860, 2510, 115, 1523, 2683, 1889, 1374, 945, 2673, 77, 116, 2206, 587, 157, 1774, 1618, 1216, 1038, 1876, 2416, 1188, 1668, 2128, 921, 2425, 385, 2482, 1579, 2943, 1026, 2605, 126, 922, 2089, 703, 172, 2101, 353, 1824, 507, 2457, 2927, 2769, 1070, 1915, 325, 745, 1542, 579, 793, 837, 692, 1224, 1463, 685, 1594, 1535, 193, 2288, 2559, 581, 516, 1234, 2846, 1371, 166, 1193, 289, 716, 2576, 802, 2538, 1218, 1464, 2716, 1410, 771, 2501, 261, 2861, 191, 2929, 1041, 1792, 37, 2722, 1490, 2593, 2637, 699, 2776, 393, 1507, 1424, 2426, 2569, 1867, 2784, 1825, 2931, 1965, 1318, 689, 268, 1584, 1251, 315, 2176, 370, 339, 1287, 2928, 1532, 746, 486, 909, 583, 1832, 479, 2894, 2031, 2583, 2280, 1363, 753, 2721, 1821, 1694, 577, 2269, 2243, 1080, 857, 331, 408, 2830, 2975, 106, 2264, 1757, 2285, 1970, 1056, 2405, 1746, 2595, 2698, 2427, 2074, 2834, 301, 3009, 1477, 454, 923, 2884, 54, 1714, 109, 811, 2139, 765, 482, 2016, 1457, 1928, 1515, 2408, 2572, 1712, 686, 2549, 2096, 78, 2113, 967, 2555, 2200, 1627, 2052, 2686, 1403, 1454, 1447, 306, 1847, 2216, 1949, 1442, 590, 2227, 616, 2709, 97, 488, 1473, 936, 2790, 2601, 2945, 1097, 33, 1055, 2317, 294, 596, 1398, 3, 722, 492, 853, 3010, 175, 2613, 738, 138, 2558, 1854, 1110, 2739, 799, 2479, 2903, 792, 764, 519, 3023, 2545, 2040, 2020, 2037, 1522, 2043, 273, 90, 1842, 1791, 2879, 951, 1607, 2118, 2791, 1972, 2525, 2663, 1930, 412, 2670, 1261, 85, 2650, 1258, 1125, 1691, 2582, 2710, 74, 391, 2908, 2749, 1134, 2002, 2587, 254, 2704, 1383, 819, 1573, 2614, 1565, 2480, 2192, 1978, 2253, 2448, 169, 869, 1763, 1417, 1240, 601, 657, 1343, 2431, 2252, 1231, 627, 2856, 872, 341, 1212, 1361, 915, 1660, 2368, 890, 2843, 2282, 2430, 831, 2279, 327, 1609, 2150, 897, 35, 2822, 1820, 2793, 797, 660, 375, 1219, 392, 972, 1943, 1101, 619, 1682, 1723, 460, 1551, 2983, 380, 2309, 1871, 2312, 1153, 1670, 1981, 2958, 2665, 321, 2522, 2057, 1184, 983, 1807, 2993, 1063, 2970, 2973, 530, 2981, 1880, 575, 120, 1275, 1591, 1541, 2100, 2867, 2197, 2301, 1411, 710, 2169, 502, 1996, 125, 2292, 1605, 2158, 2586, 176, 1911, 730, 455, 1776, 1391, 1964, 865, 1298, 1676, 2763, 726, 66, 2382, 2369, 2667, 912, 1957, 871, 1050, 728, 1895, 1543, 2992, 178, 2322, 2806, 2454, 2924, 1608, 1941, 2998, 2092, 242, 1431, 505, 1874, 1048, 1657, 1848, 377, 2313, 1606, 564, 132, 2540, 2065, 1644, 1706, 1518, 2882, 1693, 736, 490, 538, 2076, 1681, 3018, 1923, 1951, 2027, 2042, 324, 1046, 2389, 1007, 2636, 696, 529, 352, 2922, 1449, 798, 1654, 2887, 1047, 1549, 786, 1210, 443, 514, 2515, 3007, 2345, 985, 1369, 2738, 2316, 1598, 2419, 1386, 230, 2445, 531, 1480, 1500, 1289, 256, 2471, 650, 1032, 1155, 1538, 1945, 310, 629, 1053, 95, 883, 656, 1967, 2930, 594, 1009, 1695, 2727, 2120, 737, 2905, 345, 1199, 1390, 2796, 2342, 46, 854, 789, 2953, 2918, 2949, 215, 2507, 2546, 426, 1852, 654, 1992, 2144, 642, 2107, 2256, 1060, 1334, 2241, 1764, 701, 415, 304, 2073, 1071, 705, 61, 2294, 450, 425, 2428, 1905, 2623, 1918, 2550, 1407, 320, 2407, 2957, 2748, 1290, 1436, 2165, 1414, 2290, 527, 2824, 3005, 800, 247, 1128, 2893, 2053, 2387, 1768, 144, 99, 1752, 2164, 1236, 2626, 2112, 1064, 1364, 2354, 591, 1113, 1257, 1560, 775, 2517, 2429, 2668, 2487, 2591, 826, 23, 1735, 402, 2215, 2337, 2829, 220, 597, 361, 49, 1710, 2351, 506, 2195, 2185, 688, 2071, 973, 549, 2725, 2852, 1252, 2972, 1808, 2130, 2627, 2039, 2384, 410, 2680, 2506, 1806, 1998, 2839, 3014, 2831, 1497, 395, 2514, 461, 1345, 1736, 1468, 2184, 2414, 121, 2468, 1589, 2760, 1057, 2493, 2906, 2567, 803, 2532, 1136, 2508, 2490, 1191, 1959, 801, 2607, 1961, 1310, 2669, 2914, 2798, 152, 2925, 1466, 143, 774, 1596, 2211, 2594, 1758, 1434, 2554, 607, 1370, 1102, 2134, 545, 501, 576, 1504, 1137, 17, 1173, 2439, 2655, 830, 1574, 2046, 2701, 27, 2304, 957, 1708, 2868, 773, 2156, 1645, 2329, 2691, 1548, 1762, 668, 1253, 2996, 1322, 2759, 1639, 2415, 2314, 195, 1898, 1866, 1237, 2715, 155, 422, 806, 1982, 2692, 1750, 1165, 2132, 141, 697, 2919, 2750, 1659, 1207, 1037, 1302, 889, 2976, 2155, 1095, 2800, 2365, 2104, 739, 1772, 196, 252, 993, 2173, 305, 2245, 2881, 727, 958, 2117, 2278, 1339, 1795, 573, 2047, 2765, 934, 2653, 556, 1689, 2248, 2713, 149, 1662, 1679, 602, 1246, 1666, 452, 2926, 2066, 1628, 206, 551, 1727, 2678, 2694, 2937, 2718, 1496, 2023, 1054, 2551, 231, 1737, 1963, 3024, 423, 338, 1358, 614, 2344, 1658, 1291, 2038, 416, 2687, 3026, 2444, 2106, 1181, 1281, 2737, 91, 2909, 1495, 1146, 179, 427, 2803, 2768, 2180, 2102, 2948, 2816, 584, 9, 2775, 1169, 2688, 2160, 2599, 1564, 740, 2849, 1209, 279, 1545, 1325, 569, 1818, 2330, 2412, 544, 2854, 844, 2015, 1121, 2640, 2566, 437, 691, 916, 1884, 2374, 2473, 1979, 2149, 2488, 532, 1443, 1120, 2466, 1721, 981, 228, 690, 136, 560, 2995, 2920, 2353, 2907, 1485, 1690, 2615, 334, 1313, 1738, 503, 827, 2223, 949, 1805, 2123, 81, 2516, 2395, 1674, 2547, 2606, 3022, 2103, 394, 2397, 1122, 1452, 955, 2145, 1484, 188, 314, 2548, 1966, 2451, 1166, 1001, 1631, 713, 2999, 1498, 609, 1416, 1633, 1909, 387, 275, 1831, 2779, 1400, 2778, 390, 1367, 805, 2034, 540, 714, 1739, 1777, 970, 845, 2523, 1948, 818, 1107, 1160, 561, 2774, 1582, 1626, 1678, 2985, 274, 2620, 1305, 1163, 978, 226, 1561, 2406, 1932, 367, 496, 2434, 702, 1748, 1300, 2952, 832, 1580, 1888, 976, 1337, 433, 1920, 1969, 236, 954, 568, 1740, 11, 2051, 1629, 2499, 2075, 2756, 2151, 552, 762, 1502, 2693, 2808, 2178, 732, 1646, 2589, 1534, 2821, 146, 209, 2697, 69, 1456, 1803, 2221, 2088, 457, 2012, 2045, 1270, 2891, 1475, 349, 528, 1899, 2318, 852, 939, 1412, 554, 645, 2159, 1724, 65, 1931, 2099, 1204, 1778, 553, 400, 1267, 217, 272, 1474, 1030, 445, 2054, 1830, 2352, 1921, 2560, 2509, 1602, 214, 466, 2455, 123, 2319, 34, 678, 834, 1838, 2284, 677, 2396, 2947, 2460, 2959, 224, 119, 363, 2009, 2422, 71, 508, 148, 1462, 824, 769, 2153, 684, 2011, 1402, 2082, 1958, 2588, 838, 1294, 2664, 943, 431, 615, 1788, 1873, 1151, 2108, 2336, 1851, 398, 2152, 821, 2350, 2622, 430, 1713, 2911, 2064, 1042, 930, 1907, 1176, 2645, 2402, 365, 2237, 2812, 2503, 2275, 1827, 1947, 2250, 104, 1052, 40, 2565, 704, 2875, 2340, 927, 534, 2143, 20, 446, 48, 2013, 1427, 2724, 2814, 2146, 1796, 55, 1539, 1711, 2534, 2662, 1430, 2642, 243, 750, 2019, 776, 1040, 1116, 729, 1351, 1469, 2648, 2459, 2341, 548, 2777, 1459, 1006, 364, 82, 439, 72, 2883, 2782, 2048, 1091, 1546, 723, 1089, 1587, 1312, 2819, 649, 25, 599, 1082, 499, 1887, 2635, 3006, 476, 662, 1013, 2963, 1913, 2124, 2741, 992, 2097, 2521, 319, 595, 1553, 2553, 1190, 966, 2766, 2420, 1509, 58, 756, 145, 1157, 1962, 1114, 1841, 1897, 2296, 1719, 1461, 946, 2742, 628, 593, 2003, 265, 1161, 1332, 1187, 846, 1152, 1419, 2078, 2356, 1111, 1487, 1062, 200, 346, 906, 1225, 2063, 2845, 2325, 1021, 990, 856, 863, 2504, 2393, 2496, 1506, 2240, 825, 2712, 2109, 135, 2260, 429, 2446, 861, 1242, 45, 667, 537, 2190, 2379, 885, 673, 1075, 1066, 2734, 2201, 2136, 2888, 414, 1505, 287, 997, 183, 1514, 1446, 2436, 748, 1263, 87, 1280, 709, 840, 1665, 182, 1118, 3019, 3002, 1472, 98, 2827, 1536, 7, 804, 2373, 2068, 21, 1036, 2902, 1575, 2809, 842, 1074, 399, 964, 1127, 2951, 2273, 504, 794, 1409, 2349, 1770, 926, 376, 2081, 637, 1503, 251, 1652, 18, 170, 2004, 1059, 598, 36, 2528, 1650, 578, 484, 2386, 2890, 2529, 2035, 2056, 2492, 384, 2967, 1994, 2955, 1508, 2728, 337, 1147, 2526, 917, 1423, 333, 1868, 2512, 2719, 1467, 622, 539, 3021, 2892, 1853, 1799, 1802, 2862, 1304, 2828, 405, 1709, 2265, 2956, 2502, 64, 1189, 940, 1638, 2267, 533, 1379, 342, 1282, 2651, 366, 1178, 2753, 0, 2519, 708, 1172, 160, 2328, 887]\n",
            "3027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBiFQNH3yN6N",
        "outputId": "7f45389c-8ae3-4bc9-f7ad-85b038ae50f5"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2619    the professor did not make use of reallife exa...\n",
              "456     it good but we dont find the book because thei...\n",
              "102     interaction of some faculty wa good but not al...\n",
              "1126    he is one of the best teacher i have ever had ...\n",
              "1003    the lecturer wa organized and clear but they c...\n",
              "                              ...                        \n",
              "708     this course wa amazing i learned so much and i...\n",
              "1172    she say that if you understand the example fro...\n",
              "160     very knowledgeable some subject do not have de...\n",
              "2328    the professor doe not encourage active partici...\n",
              "887       dont be afraid to ask for help when you need it\n",
              "Name: reviews, Length: 3027, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_xXFxeoyRUO",
        "outputId": "2b993c60-8a9b-4570-da2f-03a2774ea80b"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2619    0\n",
              "456     1\n",
              "102     1\n",
              "1126    2\n",
              "1003    1\n",
              "       ..\n",
              "708     2\n",
              "1172    2\n",
              "160     1\n",
              "2328    0\n",
              "887     1\n",
              "Name: sentiment, Length: 3027, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training - Validation Split"
      ],
      "metadata": {
        "id": "XBbquN0qf6Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(sentences, labels, training_split):\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Compute the number of sentences that will be used for training (should be an integer)\n",
        "    train_size = int(len(sentences)*training_split)\n",
        "\n",
        "    # Split the sentences and labels into train/validation splits\n",
        "    train_sentences = sentences[:train_size]\n",
        "    train_labels = labels[:train_size]\n",
        "\n",
        "    test_sentences = sentences[train_size:]\n",
        "    test_labels = labels[train_size:]\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return train_sentences, test_sentences, train_labels, test_labels"
      ],
      "metadata": {
        "id": "BSptFFxJf8hw"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, test_sentences, train_labels, test_labels = train_val_split(sentences, labels, TRAINING_SPLIT)\n",
        "\n",
        "print(f\"There are {len(train_sentences)} sentences for training.\\n\")\n",
        "print(f\"There are {len(train_labels)} labels for training.\\n\")\n",
        "print(f\"There are {len(test_sentences)} sentences for validation.\\n\")\n",
        "print(f\"There are {len(test_labels)} labels for validation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbdiZp4LgHwo",
        "outputId": "208e0f46-61b2-423b-db7b-4b20786c6072"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2724 sentences for training.\n",
            "\n",
            "There are 2724 labels for training.\n",
            "\n",
            "There are 303 sentences for validation.\n",
            "\n",
            "There are 303 labels for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7SR4NuI6KZT",
        "outputId": "d4c540af-a7c9-4972-d710-f4682e1811f5"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2588    the professor had a rigid teaching style not a...\n",
              "838     the subject material are adequate and meet the...\n",
              "1294    the professor is a wonderful and extremely hel...\n",
              "2664    the professor demonstrated effective communica...\n",
              "943     the presenter did not use effective visuals or...\n",
              "                              ...                        \n",
              "708     this course wa amazing i learned so much and i...\n",
              "1172    she say that if you understand the example fro...\n",
              "160     very knowledgeable some subject do not have de...\n",
              "2328    the professor doe not encourage active partici...\n",
              "887       dont be afraid to ask for help when you need it\n",
              "Name: reviews, Length: 303, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization & Stopwords - Sequences, Truncating, and Padding"
      ],
      "metadata": {
        "id": "Hkha78ZLhD8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKC0bOvTe0tc",
        "outputId": "a693cf40-960c-43a0-baa0-9c5465f8f506"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stopwords"
      ],
      "metadata": {
        "id": "k09AYA_Vn2qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_file = open(\"stopwords.txt\", \"r\")\n",
        "\n",
        "data = my_file.read()\n",
        "\n",
        "stopwords_data = data.split(\"\\n\")\n",
        "print(stopwords_data)\n",
        "my_file.close()"
      ],
      "metadata": {
        "id": "iUXhqbqynJcz",
        "outputId": "e6ebea80-51a8-4130-a26e-cf433a8660b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'about', 'above', 'across', 'after', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'among', 'an', 'and', 'another', 'any', 'anybody', 'anyone', 'anything', 'anywhere', 'are', 'area', 'areas', 'around', 'as', 'ask', 'asked', 'asking', 'asks', 'at', 'away', 'b', 'back', 'backed', 'backing', 'backs', 'be', 'became', 'because', 'become', 'becomes', 'been', 'before', 'began', 'behind', 'being', 'beings', 'best', 'better', 'between', 'big', 'both', 'but', 'by', 'c', 'came', 'can', 'cannot', 'case', 'cases', 'certain', 'certainly', 'clear', 'clearly', 'come', 'could', 'd', 'did', 'differ', 'different', 'differently', 'do', 'does', 'done', 'down', 'down', 'downed', 'downing', 'downs', 'during', 'e', 'each', 'early', 'either', 'end', 'ended', 'ending', 'ends', 'enough', 'even', 'evenly', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'f', 'face', 'faces', 'fact', 'facts', 'far', 'felt', 'few', 'find', 'finds', 'first', 'for', 'four', 'from', 'full', 'fully', 'further', 'furthered', 'furthering', 'furthers', 'g', 'gave', 'general', 'generally', 'get', 'gets', 'give', 'given', 'gives', 'go', 'going', 'good', 'goods', 'got', 'great', 'greater', 'greatest', 'group', 'grouped', 'grouping', 'groups', 'h', 'had', 'has', 'have', 'having', 'he', 'her', 'here', 'herself', 'high', 'high', 'high', 'higher', 'highest', 'him', 'himself', 'his', 'how', 'however', 'i', 'if', 'important', 'in', 'interest', 'interested', 'interesting', 'interests', 'into', 'is', 'it', 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps', 'kind', 'knew', 'know', 'known', 'knows', 'l', 'large', 'largely', 'last', 'later', 'latest', 'least', 'less', 'let', 'lets', 'like', 'likely', 'long', 'longer', 'longest', 'm', 'made', 'make', 'making', 'man', 'many', 'may', 'me', 'member', 'members', 'men', 'might', 'more', 'most', 'mostly', 'mr', 'mrs', 'much', 'must', 'my', 'myself', 'n', 'necessary', 'need', 'needed', 'needing', 'needs', 'never', 'new', 'new', 'newer', 'newest', 'next', 'no', 'nobody', 'non', 'noone', 'not', 'nothing', 'now', 'nowhere', 'number', 'numbers', 'o', 'of', 'off', 'often', 'old', 'older', 'oldest', 'on', 'once', 'one', 'only', 'open', 'opened', 'opening', 'opens', 'or', 'order', 'ordered', 'ordering', 'orders', 'other', 'others', 'our', 'out', 'over', 'p', 'part', 'parted', 'parting', 'parts', 'per', 'perhaps', 'place', 'places', 'point', 'pointed', 'pointing', 'points', 'possible', 'present', 'presented', 'presenting', 'presents', 'problem', 'problems', 'put', 'puts', 'q', 'quite', 'r', 'rather', 'really', 'right', 'right', 'room', 'rooms', 's', 'said', 'same', 'saw', 'say', 'says', 'second', 'seconds', 'see', 'seem', 'seemed', 'seeming', 'seems', 'sees', 'several', 'shall', 'she', 'should', 'show', 'showed', 'showing', 'shows', 'side', 'sides', 'since', 'small', 'smaller', 'smallest', 'so', 'some', 'somebody', 'someone', 'something', 'somewhere', 'state', 'states', 'still', 'still', 'such', 'sure', 't', 'take', 'taken', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'these', 'they', 'thing', 'things', 'think', 'thinks', 'this', 'those', 'though', 'thought', 'thoughts', 'three', 'through', 'thus', 'to', 'today', 'together', 'too', 'took', 'toward', 'turn', 'turned', 'turning', 'turns', 'two', 'u', 'under', 'until', 'up', 'upon', 'us', 'use', 'used', 'uses', 'v', 'very', 'w', 'want', 'wanted', 'wanting', 'wants', 'was', 'way', 'ways', 'we', 'well', 'wells', 'went', 'were', 'what', 'when', 'where', 'whether', 'which', 'while', 'who', 'whole', 'whose', 'why', 'will', 'with', 'within', 'without', 'work', 'worked', 'working', 'works', 'would', 'x', 'y', 'year', 'years', 'yet', 'you', 'young', 'younger', 'youngest', 'your', 'yours', 'z', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(sentence, data):\n",
        "    # List of stopwords\n",
        "\n",
        "    stopwords = data + [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "    numbers_stopwords = [\"1\", \"2\", \"3\", \"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\n",
        "                         \"one\", \"two\",\"three\",\"four\",\"five\",\"098\"]\n",
        "    more_words = [\"didn't\", \"don't\", \"dont\", \"didnt\", \"it\", \"doesnt\", \"doesn't\", \"hw\",\"won't\",\"lpu\",\"weren't\",\"mr\",\"mcq\",\"shes\",\n",
        "                  \"shes\",\"india\",\"in\",\"hes\",\"shes\",\"me\", \"dr\", \"nlandu\", \"ko\",\"it\",\"1st\", \"omr\", \"ha\", \"upto\",\"ca\", \"soo\", \"cd\", \"ive\",\"po\",\"cse\", \"chem\", \"un\",\"of\",\n",
        "                  \"mte\", \"omr\",\"mte's\",\"ca's\",\"ete's\",\"jnv\",\"ip\",\"sir\",\"its\",\"wks\",\"prob\",\"python\",\"java\",\"lattc\",\"ol\",\"ived\",\"elsewhere\", \"mother\",\"wouldnt\",\"car\",\n",
        "                  \"si\", \"sat\",\"we\",\"home\",\"hot\",\"god\",\"ice\",\"money's\",\"money\",\"even\",\"about\",\"thats\", \"wks\", \"thurs\", \"months\", \"sir\", \"go\", \"jnv\", \"ip\", \"today\", \"today's\", \"linux\", \"github\",\n",
        "                  \"lt\", \"ums\", \"superb\", \"at\", \"cgpa\",\"ques\", \"brain's\", \"mcqs\", \"ve\", \"say\", \"pc\", \"viva\", \"after\", \"before\", \"draw\", \"asst\", \"only\", \"rich\", \"never\", \"went\", \"pcs\", \"gk\", \"one's\",\n",
        "                  \"co\", \"duty\", \"gona\", \"attendnce\",\"same\", \"that's\", \"hahahah\", \"ad's\", \"university's\", \"relly\", \"build\", \"cricket\", \"said\", \"hall\", \"profs\", \"guy's\", \"can\", \"along\", \"archieve\", \"bag\",\n",
        "                  \"part\", \"master\", \"push\", \"or\", \"add\", \"were\", \"virginia\",\"human\", \"bless\", \"clean\", \"count\", \"onlineopen\", \"ounce\", \"brushing\", \"zero\", \"mail\", \"fys\", \"lowell\", \"stets\", \"untill\", \"until\",\n",
        "                  \"prep\", \"appears\", \"giulia\", \"yuk\", \"memo\", \"ton\", \"110q\", \"unit\", \"80\",\"re\",\"by\",\"order\",\"fob\", \"sit\", \"from\",\"art\", \"org\", \"4d\", \"3d\", \"cinema\", \"iii\", \"cal\", \"both\", \"sundays\", \"todays\", \"ad\",\n",
        "                  \"yoursel\",\"yourself\", \"kiss\", \"it'll\", \"obayani's\", \"anal\", \"pgs\", \"csci\", \"hw\", \"more\", \"able\", \"lecturer\", \"lecturer's\", \"student\", \"stundet's\", \"it\", \"want\", \"you\",\"he's\", \"she's\"]\n",
        "    more =  [\n",
        "    'a', 'about', 'above', 'after', 'again', 'against', \"ain't\", 'all', 'am', 'an', 'and', 'any', 'are', 'aren\\'t', 'as',\n",
        "    'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'can\\'t', 'cannot',\n",
        "    'could', 'couldn\\'t', 'did', 'didn\\'t', 'do', 'does', 'doesn\\'t', 'doing', 'don\\'t', 'down', 'during', 'each', 'few',\n",
        "    'for', 'from', 'further', 'had', 'hadn\\'t', 'has', 'hasn\\'t', 'have', 'haven\\'t', 'having', 'he', 'he\\'d', 'he\\'ll',\n",
        "    'he\\'s', 'her', 'here', 'here\\'s', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'how\\'s', 'i', 'i\\'d', 'i\\'ll',\n",
        "    'i\\'m', 'i\\'ve', 'if', 'in', 'into', 'is', 'isn\\'t', 'it', 'it\\'s', 'its', 'itself', 'let\\'s', 'me', 'more', 'most',\n",
        "    'mustn\\'t', 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our',\n",
        "    'ours', 'ourselves', 'out', 'over', 'own', 'same', 'shan\\'t', 'she', 'she\\'d', 'she\\'ll', 'she\\'s', 'should',\n",
        "    'shouldn\\'t', 'so', 'some', 'such', 'than', 'that', 'that\\'s', 'the', 'their', 'theirs', 'them', 'themselves',\n",
        "    'then', 'there', 'there\\'s', 'these', 'they', 'they\\'d', 'they\\'ll', 'they\\'re', 'they\\'ve', 'this', 'those',\n",
        "    'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', 'wasn\\'t', 'we', 'we\\'d', 'we\\'ll', 'we\\'re',\n",
        "    'we\\'ve', 'were', 'weren\\'t', 'what', 'what\\'s', 'when', 'when\\'s', 'where', 'where\\'s', 'which', 'while', 'who',\n",
        "    'who\\'s', 'whom', 'why', 'why\\'s', 'with', 'won\\'t', 'would', 'wouldn\\'t', 'you', 'you\\'d', 'you\\'ll', 'you\\'re',\n",
        "    'you\\'ve', 'your', 'yours', 'yourself', 'yourselves']\n",
        "\n",
        "    final_stopwords = stopwords + numbers_stopwords + more_words + more\n",
        "\n",
        "    words = sentence.split()\n",
        "    tempWords = []\n",
        "    for i in words:\n",
        "        if i not in final_stopwords:\n",
        "            tempWords.append(i)\n",
        "            sentence = ' '.join(tempWords)\n",
        "\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "0jSROBdBn92J"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words_list = list(stop_words)\n",
        "stopwords_data = stopwords_data + stop_words_list"
      ],
      "metadata": {
        "id": "uQ0o7mPbolbS",
        "outputId": "6641a4a5-76e3-403b-f230-0d631c7303aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "response = vectorizer.fit_transform(df['reviews'])\n",
        "print(type(response))"
      ],
      "metadata": {
        "id": "EzoVVl0Sq723",
        "outputId": "564d0fc7-ec96-4c1a-be96-68e11b7da890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cKomen = []\n",
        "for i in range(len(df)):\n",
        "  cKomen.append(remove_stopwords(df['reviews'][i], stopwords_data))\n",
        "\n",
        "df['reviews'] = cKomen"
      ],
      "metadata": {
        "id": "OVLg8mUcoQGS"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = df.copy()\n",
        "final_data['reviews'][2619]\n",
        "# final_data['sentiment'][2619]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kshZo9KctRUj",
        "outputId": "e6295ff2-0072-4def-ab4d-d358d4afd468"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'professor reallife example study illustrate concept theory'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.to_csv('final_data.csv')"
      ],
      "metadata": {
        "id": "73t-xlDUtg5b"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: fit_tokenizer\n",
        "def fit_tokenizer(sentences, oov_token):\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Instantiate the Tokenizer class, passing in the correct values for oov_token\n",
        "    tokenizer = Tokenizer(oov_token = OOV_TOKEN)\n",
        "\n",
        "    # Fit the tokenizer to the training sentences\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "Ysf5VZ_hhITo"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function\n",
        "tokenizer = fit_tokenizer(train_sentences, OOV_TOKEN)\n",
        "word_index = tokenizer.word_index\n",
        "VOCAB_SIZE = len(word_index)\n",
        "\n",
        "print(f\"Vocabulary contains {VOCAB_SIZE} words\\n\")\n",
        "print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")\n",
        "print(f\"\\nindex of word 'i' should be {word_index['i']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hy5fTzvhMMm",
        "outputId": "bc677fd0-3e1c-4cd9-9ac7-58cc205a69ba"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary contains 3669 words\n",
            "\n",
            "<OOV> token included in vocabulary\n",
            "\n",
            "index of word 'i' should be 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_pad_and_trunc(sentences, tokenizer, padding, truncating, maxlen):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    pad_trunc_sequences = pad_sequences(sequences, maxlen= MAXLEN, padding = PADDING, truncating = TRUNCATING)\n",
        "    return pad_trunc_sequences"
      ],
      "metadata": {
        "id": "xUkJFtiwh7C-"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pad_trunc_seq = seq_pad_and_trunc(train_sentences, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
        "val_pad_trunc_seq = seq_pad_and_trunc(test_sentences, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
        "\n",
        "print(f\"Padded and truncated training sequences have shape: {train_pad_trunc_seq.shape}\\n\")\n",
        "print(f\"Padded and truncated validation sequences have shape: {val_pad_trunc_seq.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biCCj27uh-Ve",
        "outputId": "04b88734-c4e7-40b5-a76b-0ec6aea014e3"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded and truncated training sequences have shape: (2724, 16)\n",
            "\n",
            "Padded and truncated validation sequences have shape: (303, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_labels)\n",
        "val_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "OR3wfthriCnN"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using pre-defined Embeddings"
      ],
      "metadata": {
        "id": "j0j16iy7iI-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path to file containing the embeddings\n",
        "GLOVE_FILE = 'glove.6B.100d.txt'\n",
        "\n",
        "# Initialize an empty embeddings index dictionary\n",
        "GLOVE_EMBEDDINGS = {}\n",
        "\n",
        "# Read file and fill GLOVE_EMBEDDINGS with its contents\n",
        "with open(GLOVE_FILE) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        GLOVE_EMBEDDINGS[word] = coefs"
      ],
      "metadata": {
        "id": "tUHybcFMiE0d"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Represent the words in your vocabulary using the embeddings"
      ],
      "metadata": {
        "id": "ldaN0eawl5v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty numpy array with the appropriate size\n",
        "EMBEDDINGS_MATRIX = np.zeros((VOCAB_SIZE+1, EMBEDDING_DIM))\n",
        "\n",
        "# Iterate all of the words in the vocabulary and if the vector representation for\n",
        "# each word exists within GloVe's representations, save it in the EMBEDDINGS_MATRIX array\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = GLOVE_EMBEDDINGS.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        EMBEDDINGS_MATRIX[i] = embedding_vector"
      ],
      "metadata": {
        "id": "Rokt-fwRl8NB"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a model that does not overfit"
      ],
      "metadata": {
        "id": "HZjjYxbzl8ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with 0.001 learning rate"
      ],
      "metadata": {
        "id": "QPn--pNsDhEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_model(vocab_size, embedding_dim, maxlen, embeddings_matrix):\n",
        "#     model = tf.keras.Sequential([\n",
        "#         # This is how you need to set the Embedding layer when using pre-trained embeddings\n",
        "#         tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=maxlen, weights=[embeddings_matrix], trainable=False),\n",
        "#         tf.keras.layers.Conv1D(32, 5, activation='relu'),\n",
        "#         tf.keras.layers.GlobalMaxPooling1D(),\n",
        "#         tf.keras.layers.Dropout(0.2),\n",
        "#         tf.keras.layers.Dense(32, activation='relu'),\n",
        "#         tf.keras.layers.Dense(3, activation='softmax'),\n",
        "#     ])\n",
        "\n",
        "#     model.compile(loss='sparse_categorical_crossentropy',\n",
        "#                   optimizer='adam',\n",
        "#                   metrics=['accuracy'])\n",
        "#     return model"
      ],
      "metadata": {
        "id": "HAWbMeF-mBg5"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with 0.002 learning rate"
      ],
      "metadata": {
        "id": "_iIk4pY1DcZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def create_model(vocab_size, embedding_dim, maxlen, embeddings_matrix):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=maxlen, weights=[embeddings_matrix], trainable=False),\n",
        "        tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(3, activation='softmax'),\n",
        "    ])\n",
        "    optimizer = optimizers.Adam(learning_rate = 0.002)\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "eLywL_aR9KSf"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with 0.0025 learning rate"
      ],
      "metadata": {
        "id": "ewJcvwnoIwCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras import optimizers\n",
        "\n",
        "# def create_model(vocab_size, embedding_dim, maxlen, embeddings_matrix):\n",
        "#     model = tf.keras.Sequential([\n",
        "#         tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=maxlen, weights=[embeddings_matrix], trainable=False),\n",
        "#         tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "#         tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "#         tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
        "#         tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "#         tf.keras.layers.Dense(64, activation='relu'),\n",
        "#         tf.keras.layers.Dropout(0.2),\n",
        "#         tf.keras.layers.Dense(3, activation='softmax'),\n",
        "#     ])\n",
        "#     optimizer = optimizers.Adam(learning_rate = 0.0025)\n",
        "#     model.compile(loss='sparse_categorical_crossentropy',\n",
        "#                   optimizer=optimizer,\n",
        "#                   metrics=['accuracy'])\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "BB31XCglDbsW"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(VOCAB_SIZE, EMBEDDING_DIM, MAXLEN, EMBEDDINGS_MATRIX)"
      ],
      "metadata": {
        "id": "ePMfJY5UKPB4"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZnbOCPTQ_QK",
        "outputId": "b3587dec-69f4-4a0d-8fed-ec62b6e19dd4"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 16, 100)           367000    \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 14, 64)            19264     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 7, 64)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 7, 128)           49920     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 64)               31104     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 471,643\n",
            "Trainable params: 104,643\n",
            "Non-trainable params: 367,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model and save the training history\n",
        "history = model.fit(train_pad_trunc_seq, train_labels, epochs=200, validation_data=(val_pad_trunc_seq, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArRf_nFcmEjZ",
        "outputId": "049cce48-f5c7-44a7-c38f-adc505eed967"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "86/86 [==============================] - 17s 24ms/step - loss: 0.9045 - accuracy: 0.5925 - val_loss: 0.7880 - val_accuracy: 0.6766\n",
            "Epoch 2/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.6839 - accuracy: 0.7181 - val_loss: 0.6799 - val_accuracy: 0.7459\n",
            "Epoch 3/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.5636 - accuracy: 0.7823 - val_loss: 0.6524 - val_accuracy: 0.7327\n",
            "Epoch 4/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.4568 - accuracy: 0.8245 - val_loss: 0.6705 - val_accuracy: 0.7426\n",
            "Epoch 5/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.4020 - accuracy: 0.8513 - val_loss: 0.6345 - val_accuracy: 0.7690\n",
            "Epoch 6/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.3043 - accuracy: 0.8957 - val_loss: 0.8239 - val_accuracy: 0.7294\n",
            "Epoch 7/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.2543 - accuracy: 0.9108 - val_loss: 0.7925 - val_accuracy: 0.7096\n",
            "Epoch 8/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.2183 - accuracy: 0.9288 - val_loss: 0.9696 - val_accuracy: 0.7459\n",
            "Epoch 9/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1748 - accuracy: 0.9416 - val_loss: 0.9744 - val_accuracy: 0.7459\n",
            "Epoch 10/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1313 - accuracy: 0.9559 - val_loss: 1.1347 - val_accuracy: 0.7096\n",
            "Epoch 11/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1033 - accuracy: 0.9670 - val_loss: 1.2802 - val_accuracy: 0.7096\n",
            "Epoch 12/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1070 - accuracy: 0.9615 - val_loss: 1.1774 - val_accuracy: 0.6865\n",
            "Epoch 13/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1420 - accuracy: 0.9512 - val_loss: 1.2106 - val_accuracy: 0.6997\n",
            "Epoch 14/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0826 - accuracy: 0.9706 - val_loss: 1.3028 - val_accuracy: 0.7162\n",
            "Epoch 15/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0764 - accuracy: 0.9747 - val_loss: 1.3809 - val_accuracy: 0.7294\n",
            "Epoch 16/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0892 - accuracy: 0.9692 - val_loss: 1.5220 - val_accuracy: 0.6931\n",
            "Epoch 17/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0409 - accuracy: 0.9872 - val_loss: 1.5857 - val_accuracy: 0.7228\n",
            "Epoch 18/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0595 - accuracy: 0.9783 - val_loss: 1.6191 - val_accuracy: 0.7162\n",
            "Epoch 19/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0401 - accuracy: 0.9853 - val_loss: 1.6474 - val_accuracy: 0.6997\n",
            "Epoch 20/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0492 - accuracy: 0.9816 - val_loss: 1.7107 - val_accuracy: 0.7327\n",
            "Epoch 21/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0423 - accuracy: 0.9853 - val_loss: 1.9122 - val_accuracy: 0.7030\n",
            "Epoch 22/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0405 - accuracy: 0.9831 - val_loss: 1.6940 - val_accuracy: 0.7558\n",
            "Epoch 23/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0531 - accuracy: 0.9791 - val_loss: 1.5905 - val_accuracy: 0.7129\n",
            "Epoch 24/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0472 - accuracy: 0.9816 - val_loss: 1.7061 - val_accuracy: 0.7162\n",
            "Epoch 25/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0366 - accuracy: 0.9864 - val_loss: 1.6848 - val_accuracy: 0.7492\n",
            "Epoch 26/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0423 - accuracy: 0.9846 - val_loss: 2.0795 - val_accuracy: 0.6733\n",
            "Epoch 27/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0661 - accuracy: 0.9776 - val_loss: 1.7800 - val_accuracy: 0.7096\n",
            "Epoch 28/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0406 - accuracy: 0.9849 - val_loss: 1.5794 - val_accuracy: 0.7360\n",
            "Epoch 29/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 1.6946 - val_accuracy: 0.7327\n",
            "Epoch 30/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0268 - accuracy: 0.9894 - val_loss: 1.7629 - val_accuracy: 0.7195\n",
            "Epoch 31/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0265 - accuracy: 0.9897 - val_loss: 1.9370 - val_accuracy: 0.7228\n",
            "Epoch 32/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0407 - accuracy: 0.9849 - val_loss: 1.6049 - val_accuracy: 0.7294\n",
            "Epoch 33/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 2.2146 - val_accuracy: 0.6865\n",
            "Epoch 34/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0652 - accuracy: 0.9780 - val_loss: 1.9360 - val_accuracy: 0.7294\n",
            "Epoch 35/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0464 - accuracy: 0.9816 - val_loss: 1.6179 - val_accuracy: 0.7294\n",
            "Epoch 36/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1232 - accuracy: 0.9607 - val_loss: 1.6944 - val_accuracy: 0.7129\n",
            "Epoch 37/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 1.9606 - val_accuracy: 0.6799\n",
            "Epoch 38/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0149 - accuracy: 0.9930 - val_loss: 2.1073 - val_accuracy: 0.7327\n",
            "Epoch 39/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0115 - accuracy: 0.9938 - val_loss: 2.1023 - val_accuracy: 0.7162\n",
            "Epoch 40/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0286 - accuracy: 0.9890 - val_loss: 1.9379 - val_accuracy: 0.7459\n",
            "Epoch 41/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0282 - accuracy: 0.9894 - val_loss: 2.0082 - val_accuracy: 0.7030\n",
            "Epoch 42/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 2.1228 - val_accuracy: 0.7096\n",
            "Epoch 43/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 2.2701 - val_accuracy: 0.7030\n",
            "Epoch 44/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0074 - accuracy: 0.9952 - val_loss: 2.3406 - val_accuracy: 0.6997\n",
            "Epoch 45/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 2.3840 - val_accuracy: 0.7030\n",
            "Epoch 46/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9945 - val_loss: 2.4296 - val_accuracy: 0.6997\n",
            "Epoch 47/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0069 - accuracy: 0.9949 - val_loss: 2.4647 - val_accuracy: 0.6997\n",
            "Epoch 48/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0072 - accuracy: 0.9949 - val_loss: 2.4613 - val_accuracy: 0.7063\n",
            "Epoch 49/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0068 - accuracy: 0.9963 - val_loss: 2.4806 - val_accuracy: 0.7096\n",
            "Epoch 50/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0070 - accuracy: 0.9960 - val_loss: 2.4572 - val_accuracy: 0.7129\n",
            "Epoch 51/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 2.4378 - val_accuracy: 0.7063\n",
            "Epoch 52/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 2.3432 - val_accuracy: 0.7162\n",
            "Epoch 53/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 0.9949 - val_loss: 2.4675 - val_accuracy: 0.7195\n",
            "Epoch 54/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.5671 - val_accuracy: 0.7162\n",
            "Epoch 55/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9949 - val_loss: 2.5815 - val_accuracy: 0.7162\n",
            "Epoch 56/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9960 - val_loss: 2.6237 - val_accuracy: 0.7162\n",
            "Epoch 57/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.6670 - val_accuracy: 0.7129\n",
            "Epoch 58/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.6946 - val_accuracy: 0.7162\n",
            "Epoch 59/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 2.7185 - val_accuracy: 0.7096\n",
            "Epoch 60/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9952 - val_loss: 2.7308 - val_accuracy: 0.7162\n",
            "Epoch 61/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9967 - val_loss: 2.7494 - val_accuracy: 0.7129\n",
            "Epoch 62/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 2.7625 - val_accuracy: 0.7063\n",
            "Epoch 63/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0064 - accuracy: 0.9952 - val_loss: 2.7632 - val_accuracy: 0.7096\n",
            "Epoch 64/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0068 - accuracy: 0.9949 - val_loss: 2.7827 - val_accuracy: 0.7096\n",
            "Epoch 65/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 2.7868 - val_accuracy: 0.7129\n",
            "Epoch 66/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0083 - accuracy: 0.9956 - val_loss: 2.6450 - val_accuracy: 0.6964\n",
            "Epoch 67/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.2396 - accuracy: 0.9233 - val_loss: 1.2562 - val_accuracy: 0.7195\n",
            "Epoch 68/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1065 - accuracy: 0.9640 - val_loss: 1.4070 - val_accuracy: 0.6964\n",
            "Epoch 69/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0866 - accuracy: 0.9699 - val_loss: 1.4628 - val_accuracy: 0.7228\n",
            "Epoch 70/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0464 - accuracy: 0.9842 - val_loss: 1.5070 - val_accuracy: 0.7327\n",
            "Epoch 71/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0238 - accuracy: 0.9897 - val_loss: 1.7123 - val_accuracy: 0.7393\n",
            "Epoch 72/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0296 - accuracy: 0.9894 - val_loss: 1.8610 - val_accuracy: 0.7294\n",
            "Epoch 73/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0260 - accuracy: 0.9897 - val_loss: 1.9144 - val_accuracy: 0.6997\n",
            "Epoch 74/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0210 - accuracy: 0.9901 - val_loss: 1.8578 - val_accuracy: 0.7327\n",
            "Epoch 75/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0107 - accuracy: 0.9949 - val_loss: 1.9470 - val_accuracy: 0.7129\n",
            "Epoch 76/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0071 - accuracy: 0.9960 - val_loss: 2.0512 - val_accuracy: 0.7129\n",
            "Epoch 77/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0067 - accuracy: 0.9952 - val_loss: 2.0876 - val_accuracy: 0.7129\n",
            "Epoch 78/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 2.1246 - val_accuracy: 0.7096\n",
            "Epoch 79/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0063 - accuracy: 0.9967 - val_loss: 2.1908 - val_accuracy: 0.7096\n",
            "Epoch 80/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0074 - accuracy: 0.9960 - val_loss: 2.2260 - val_accuracy: 0.7129\n",
            "Epoch 81/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 2.2057 - val_accuracy: 0.7162\n",
            "Epoch 82/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 2.2522 - val_accuracy: 0.7162\n",
            "Epoch 83/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9960 - val_loss: 2.2972 - val_accuracy: 0.7162\n",
            "Epoch 84/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 2.2793 - val_accuracy: 0.7162\n",
            "Epoch 85/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9960 - val_loss: 2.3026 - val_accuracy: 0.7162\n",
            "Epoch 86/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 2.3101 - val_accuracy: 0.7162\n",
            "Epoch 87/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9963 - val_loss: 2.3463 - val_accuracy: 0.7129\n",
            "Epoch 88/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0060 - accuracy: 0.9963 - val_loss: 2.3860 - val_accuracy: 0.7162\n",
            "Epoch 89/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9956 - val_loss: 2.3772 - val_accuracy: 0.7162\n",
            "Epoch 90/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9952 - val_loss: 2.3630 - val_accuracy: 0.7195\n",
            "Epoch 91/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9945 - val_loss: 2.3842 - val_accuracy: 0.7129\n",
            "Epoch 92/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 0.9952 - val_loss: 2.3966 - val_accuracy: 0.7129\n",
            "Epoch 93/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0070 - accuracy: 0.9956 - val_loss: 2.4143 - val_accuracy: 0.7129\n",
            "Epoch 94/200\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.0067 - accuracy: 0.9952 - val_loss: 2.4174 - val_accuracy: 0.7129\n",
            "Epoch 95/200\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.0064 - accuracy: 0.9956 - val_loss: 2.4331 - val_accuracy: 0.7129\n",
            "Epoch 96/200\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 2.3549 - val_accuracy: 0.7261\n",
            "Epoch 97/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 0.9960 - val_loss: 2.3819 - val_accuracy: 0.7195\n",
            "Epoch 98/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0070 - accuracy: 0.9945 - val_loss: 2.4877 - val_accuracy: 0.7162\n",
            "Epoch 99/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 2.2347 - val_accuracy: 0.7228\n",
            "Epoch 100/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.2034 - accuracy: 0.9277 - val_loss: 1.0147 - val_accuracy: 0.7096\n",
            "Epoch 101/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0862 - accuracy: 0.9695 - val_loss: 1.5404 - val_accuracy: 0.7195\n",
            "Epoch 102/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.1835 - accuracy: 0.9372 - val_loss: 1.2745 - val_accuracy: 0.7228\n",
            "Epoch 103/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 1.5228 - val_accuracy: 0.7294\n",
            "Epoch 104/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 1.8031 - val_accuracy: 0.7195\n",
            "Epoch 105/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 1.7687 - val_accuracy: 0.7393\n",
            "Epoch 106/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0084 - accuracy: 0.9952 - val_loss: 1.8749 - val_accuracy: 0.7327\n",
            "Epoch 107/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0076 - accuracy: 0.9949 - val_loss: 1.9488 - val_accuracy: 0.7294\n",
            "Epoch 108/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 2.0026 - val_accuracy: 0.7294\n",
            "Epoch 109/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0072 - accuracy: 0.9960 - val_loss: 2.0273 - val_accuracy: 0.7294\n",
            "Epoch 110/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0085 - accuracy: 0.9949 - val_loss: 2.0274 - val_accuracy: 0.7294\n",
            "Epoch 111/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9967 - val_loss: 2.0667 - val_accuracy: 0.7261\n",
            "Epoch 112/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 2.1033 - val_accuracy: 0.7327\n",
            "Epoch 113/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9956 - val_loss: 2.1196 - val_accuracy: 0.7327\n",
            "Epoch 114/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 2.1478 - val_accuracy: 0.7294\n",
            "Epoch 115/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 2.1950 - val_accuracy: 0.7261\n",
            "Epoch 116/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9952 - val_loss: 2.2348 - val_accuracy: 0.7327\n",
            "Epoch 117/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0070 - accuracy: 0.9949 - val_loss: 2.2620 - val_accuracy: 0.7327\n",
            "Epoch 118/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 2.2939 - val_accuracy: 0.7327\n",
            "Epoch 119/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9960 - val_loss: 2.3061 - val_accuracy: 0.7294\n",
            "Epoch 120/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 2.3217 - val_accuracy: 0.7327\n",
            "Epoch 121/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.3355 - val_accuracy: 0.7294\n",
            "Epoch 122/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 2.3461 - val_accuracy: 0.7294\n",
            "Epoch 123/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0075 - accuracy: 0.9956 - val_loss: 2.2421 - val_accuracy: 0.7162\n",
            "Epoch 124/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0085 - accuracy: 0.9960 - val_loss: 2.2993 - val_accuracy: 0.7228\n",
            "Epoch 125/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0077 - accuracy: 0.9960 - val_loss: 2.2820 - val_accuracy: 0.7327\n",
            "Epoch 126/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 2.3455 - val_accuracy: 0.7096\n",
            "Epoch 127/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.1365 - accuracy: 0.9556 - val_loss: 1.2037 - val_accuracy: 0.7492\n",
            "Epoch 128/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.1098 - accuracy: 0.9618 - val_loss: 1.4749 - val_accuracy: 0.7327\n",
            "Epoch 129/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0436 - accuracy: 0.9838 - val_loss: 1.6887 - val_accuracy: 0.7228\n",
            "Epoch 130/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0590 - accuracy: 0.9794 - val_loss: 1.6529 - val_accuracy: 0.7195\n",
            "Epoch 131/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0266 - accuracy: 0.9897 - val_loss: 2.0308 - val_accuracy: 0.7129\n",
            "Epoch 132/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0143 - accuracy: 0.9941 - val_loss: 1.8545 - val_accuracy: 0.7327\n",
            "Epoch 133/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 1.9198 - val_accuracy: 0.7360\n",
            "Epoch 134/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0161 - accuracy: 0.9923 - val_loss: 2.0482 - val_accuracy: 0.7360\n",
            "Epoch 135/200\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.0135 - accuracy: 0.9930 - val_loss: 2.1935 - val_accuracy: 0.7294\n",
            "Epoch 136/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0077 - accuracy: 0.9963 - val_loss: 2.3379 - val_accuracy: 0.7261\n",
            "Epoch 137/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 2.4145 - val_accuracy: 0.7426\n",
            "Epoch 138/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9956 - val_loss: 2.3942 - val_accuracy: 0.7261\n",
            "Epoch 139/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0072 - accuracy: 0.9956 - val_loss: 2.4163 - val_accuracy: 0.7261\n",
            "Epoch 140/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 2.4565 - val_accuracy: 0.7294\n",
            "Epoch 141/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 2.4679 - val_accuracy: 0.7261\n",
            "Epoch 142/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 2.4833 - val_accuracy: 0.7327\n",
            "Epoch 143/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9963 - val_loss: 2.5231 - val_accuracy: 0.7294\n",
            "Epoch 144/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9952 - val_loss: 2.5333 - val_accuracy: 0.7327\n",
            "Epoch 145/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9952 - val_loss: 2.5280 - val_accuracy: 0.7327\n",
            "Epoch 146/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9949 - val_loss: 2.5513 - val_accuracy: 0.7327\n",
            "Epoch 147/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.5497 - val_accuracy: 0.7360\n",
            "Epoch 148/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9963 - val_loss: 2.5781 - val_accuracy: 0.7360\n",
            "Epoch 149/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9967 - val_loss: 2.6027 - val_accuracy: 0.7327\n",
            "Epoch 150/200\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 2.6079 - val_accuracy: 0.7360\n",
            "Epoch 151/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.6068 - val_accuracy: 0.7360\n",
            "Epoch 152/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9963 - val_loss: 2.6283 - val_accuracy: 0.7327\n",
            "Epoch 153/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.6486 - val_accuracy: 0.7360\n",
            "Epoch 154/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9960 - val_loss: 2.6528 - val_accuracy: 0.7393\n",
            "Epoch 155/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 2.6541 - val_accuracy: 0.7360\n",
            "Epoch 156/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9952 - val_loss: 2.6638 - val_accuracy: 0.7393\n",
            "Epoch 157/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9952 - val_loss: 2.6921 - val_accuracy: 0.7393\n",
            "Epoch 158/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 0.9952 - val_loss: 2.7126 - val_accuracy: 0.7393\n",
            "Epoch 159/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 0.9952 - val_loss: 2.7118 - val_accuracy: 0.7393\n",
            "Epoch 160/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 2.7358 - val_accuracy: 0.7360\n",
            "Epoch 161/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.7364 - val_accuracy: 0.7393\n",
            "Epoch 162/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9952 - val_loss: 2.7609 - val_accuracy: 0.7393\n",
            "Epoch 163/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9967 - val_loss: 2.7794 - val_accuracy: 0.7327\n",
            "Epoch 164/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0067 - accuracy: 0.9945 - val_loss: 2.7601 - val_accuracy: 0.7393\n",
            "Epoch 165/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.7371 - val_accuracy: 0.7426\n",
            "Epoch 166/200\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 0.0110 - accuracy: 0.9952 - val_loss: 2.6783 - val_accuracy: 0.7228\n",
            "Epoch 167/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.2012 - accuracy: 0.9317 - val_loss: 1.0137 - val_accuracy: 0.7327\n",
            "Epoch 168/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0855 - accuracy: 0.9703 - val_loss: 1.3201 - val_accuracy: 0.7360\n",
            "Epoch 169/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0526 - accuracy: 0.9816 - val_loss: 1.6517 - val_accuracy: 0.7393\n",
            "Epoch 170/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0277 - accuracy: 0.9894 - val_loss: 1.6898 - val_accuracy: 0.7591\n",
            "Epoch 171/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0199 - accuracy: 0.9908 - val_loss: 1.7151 - val_accuracy: 0.7426\n",
            "Epoch 172/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0369 - accuracy: 0.9897 - val_loss: 1.6956 - val_accuracy: 0.7294\n",
            "Epoch 173/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 1.6014 - val_accuracy: 0.7393\n",
            "Epoch 174/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0111 - accuracy: 0.9952 - val_loss: 1.9244 - val_accuracy: 0.7228\n",
            "Epoch 175/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0072 - accuracy: 0.9956 - val_loss: 1.9820 - val_accuracy: 0.7360\n",
            "Epoch 176/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9949 - val_loss: 2.0444 - val_accuracy: 0.7327\n",
            "Epoch 177/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9956 - val_loss: 2.0699 - val_accuracy: 0.7459\n",
            "Epoch 178/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.1001 - val_accuracy: 0.7426\n",
            "Epoch 179/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 2.1367 - val_accuracy: 0.7360\n",
            "Epoch 180/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.1710 - val_accuracy: 0.7327\n",
            "Epoch 181/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 0.9960 - val_loss: 2.1884 - val_accuracy: 0.7327\n",
            "Epoch 182/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9967 - val_loss: 2.2095 - val_accuracy: 0.7393\n",
            "Epoch 183/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.2121 - val_accuracy: 0.7327\n",
            "Epoch 184/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9949 - val_loss: 2.2134 - val_accuracy: 0.7360\n",
            "Epoch 185/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9952 - val_loss: 2.2394 - val_accuracy: 0.7360\n",
            "Epoch 186/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9949 - val_loss: 2.2595 - val_accuracy: 0.7393\n",
            "Epoch 187/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.2884 - val_accuracy: 0.7327\n",
            "Epoch 188/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9952 - val_loss: 2.2945 - val_accuracy: 0.7360\n",
            "Epoch 189/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.3074 - val_accuracy: 0.7393\n",
            "Epoch 190/200\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.0068 - accuracy: 0.9952 - val_loss: 2.3448 - val_accuracy: 0.7393\n",
            "Epoch 191/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 2.3500 - val_accuracy: 0.7393\n",
            "Epoch 192/200\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.3717 - val_accuracy: 0.7393\n",
            "Epoch 193/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0064 - accuracy: 0.9956 - val_loss: 2.3868 - val_accuracy: 0.7393\n",
            "Epoch 194/200\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.0063 - accuracy: 0.9956 - val_loss: 2.4071 - val_accuracy: 0.7393\n",
            "Epoch 195/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9960 - val_loss: 2.4256 - val_accuracy: 0.7393\n",
            "Epoch 196/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9952 - val_loss: 2.4463 - val_accuracy: 0.7393\n",
            "Epoch 197/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 2.4638 - val_accuracy: 0.7393\n",
            "Epoch 198/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9956 - val_loss: 2.4552 - val_accuracy: 0.7393\n",
            "Epoch 199/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9967 - val_loss: 2.4680 - val_accuracy: 0.7393\n",
            "Epoch 200/200\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 2.4872 - val_accuracy: 0.7393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Make predictions on the validation set\n",
        "val_predictions = model.predict(val_pad_trunc_seq)\n",
        "val_predicted_labels = np.argmax(val_predictions, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(val_labels, val_predicted_labels, average='weighted')\n",
        "recall = recall_score(val_labels, val_predicted_labels, average='weighted')\n",
        "f1 = f1_score(val_labels, val_predicted_labels, average='weighted')\n",
        "\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1-score: \", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icfjRpZh0Pao",
        "outputId": "e056f295-241b-479d-e964-f244e9061489"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 4ms/step\n",
            "Precision:  0.7415801782158803\n",
            "Recall:  0.7392739273927392\n",
            "F1-score:  0.7395195516742685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the evaluation metrics, our model performs relatively well with relatively high values of precision, recall, and F1-score"
      ],
      "metadata": {
        "id": "Z8LTrwH3183K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "OQ3kZzdTxbfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have trained the model and obtained the history\n",
        "\n",
        "# Random text for prediction\n",
        "random_text = \"good teaching\"\n",
        "\n",
        "# Tokenize the random text\n",
        "random_text_sequence = tokenizer.texts_to_sequences([random_text])\n",
        "\n",
        "# Pad and truncate the sequence\n",
        "random_text_sequence = pad_sequences(random_text_sequence, maxlen=MAXLEN, padding=PADDING, truncating=TRUNCATING)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(random_text_sequence)[0]\n",
        "\n",
        "# Convert prediction to sentiment label\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Map sentiment label to sentiment interpretation\n",
        "sentiment = \"Positive\" if predicted_label == 2 else \"Neutral\" if predicted_label == 1 else \"Negative\"\n",
        "\n",
        "# Print the prediction result\n",
        "print(f\"Text: {random_text}\")\n",
        "print(f\"Predicted Sentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "id": "unF3XUmIzde8",
        "outputId": "809e60b4-9679-476f-a436-92a90487931c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "Text: good teaching\n",
            "Predicted Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random text for prediction\n",
        "random_text = \"Bad at teaching\"\n",
        "\n",
        "# Tokenize the random text\n",
        "random_text_sequence = tokenizer.texts_to_sequences([random_text])\n",
        "random_text_sequence = pad_sequences(random_text_sequence, maxlen=MAXLEN, padding=PADDING, truncating=TRUNCATING)\n",
        "random_text_sequence"
      ],
      "metadata": {
        "id": "fJW1tCA4x4mA",
        "outputId": "d48b88ef-ac16-4075-97c2-1d4229a21741",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[152,  61,  62,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(random_text_sequence)[0]"
      ],
      "metadata": {
        "id": "GlpY4lfA0Amw",
        "outputId": "7812114e-5efb-4169-a4c0-8b24b6471185",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction\n",
        "# Convert prediction to sentiment label\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Map sentiment label to sentiment interpretation\n",
        "sentiment = \"Positive\" if predicted_label == 2 else \"Neutral\" if predicted_label == 1 else \"Negative\""
      ],
      "metadata": {
        "id": "7jzcy6_k0IcT"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment"
      ],
      "metadata": {
        "id": "nPuumBWW0J4Z",
        "outputId": "fd2c3f32-2e84-4581-e11b-8fbf8687815f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have trained the model and obtained the history\n",
        "\n",
        "# Random text for prediction\n",
        "random_text = \"The lectures for this subject were absolutely outstanding! The lecturer was highly knowledgeable and made the content engaging. I thoroughly enjoyed every session\"\n",
        "\n",
        "# Tokenize the random text\n",
        "random_text_sequence = tokenizer.texts_to_sequences([random_text])\n",
        "\n",
        "# Pad and truncate the sequence\n",
        "random_text_sequence = pad_sequences(random_text_sequence, maxlen=MAXLEN, padding=PADDING, truncating=TRUNCATING)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(random_text_sequence)[0]\n",
        "\n",
        "# Convert prediction to sentiment label\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Map sentiment label to sentiment interpretation\n",
        "sentiment = \"Positive\" if predicted_label == 2 else \"Neutral\" if predicted_label == 1 else \"Negative\"\n",
        "\n",
        "# Print the prediction result\n",
        "print(f\"Text: {random_text}\")\n",
        "print(f\"Predicted Sentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB47BcAg5PVF",
        "outputId": "9b704a37-041a-47f4-ee9f-9f190398c3cf"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "Text: The lectures for this subject were absolutely outstanding! The lecturer was highly knowledgeable and made the content engaging. I thoroughly enjoyed every session\n",
            "Predicted Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have trained the model and obtained the history\n",
        "\n",
        "# Random text for prediction\n",
        "random_text = \" I found the lectures for this subject to be incredibly boring and uninspiring. The lecturer lacked enthusiasm and failed to effectively communicate the material. It was a struggle to stay engaged throughout the course\"\n",
        "\n",
        "# Tokenize the random text\n",
        "random_text_sequence = tokenizer.texts_to_sequences([random_text])\n",
        "\n",
        "# Pad and truncate the sequence\n",
        "random_text_sequence = pad_sequences(random_text_sequence, maxlen=MAXLEN, padding=PADDING, truncating=TRUNCATING)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(random_text_sequence)[0]\n",
        "\n",
        "# Convert prediction to sentiment label\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Map sentiment label to sentiment interpretation\n",
        "sentiment = \"Positive\" if predicted_label == 2 else \"Neutral\" if predicted_label == 1 else \"Negative\"\n",
        "\n",
        "# Print the prediction result\n",
        "print(f\"Text: {random_text}\")\n",
        "print(f\"Predicted Sentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkeDm_Ar7MS6",
        "outputId": "ebb90fec-79c4-4664-cf0a-5e5d9224e888"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n",
            "Text:  I found the lectures for this subject to be incredibly boring and uninspiring. The lecturer lacked enthusiasm and failed to effectively communicate the material. It was a struggle to stay engaged throughout the course\n",
            "Predicted Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have trained the model and obtained the history\n",
        "\n",
        "# Random text for prediction\n",
        "random_text = \"The lectures for this subject were average. The lecturer was competent in delivering the content, but it lacked the wow factor. It was neither exceptional nor disappointing\"\n",
        "\n",
        "# Tokenize the random text\n",
        "random_text_sequence = tokenizer.texts_to_sequences([random_text])\n",
        "\n",
        "# Pad and truncate the sequence\n",
        "random_text_sequence = pad_sequences(random_text_sequence, maxlen=MAXLEN, padding=PADDING, truncating=TRUNCATING)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(random_text_sequence)[0]\n",
        "\n",
        "# Convert prediction to sentiment label\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Map sentiment label to sentiment interpretation\n",
        "sentiment = \"Positive\" if predicted_label == 2 else \"Neutral\" if predicted_label == 1 else \"Negative\"\n",
        "\n",
        "# Print the prediction result\n",
        "print(f\"Text: {random_text}\")\n",
        "print(f\"Predicted Sentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHy1KnhJ764C",
        "outputId": "58300be0-7149-40c7-bb49-181b87cfecb4"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "Text: The lectures for this subject were average. The lecturer was competent in delivering the content, but it lacked the wow factor. It was neither exceptional nor disappointing\n",
            "Predicted Sentiment: Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['reviews'][887]\n",
        "df['sentiment'][887]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzmZAwvt6OLT",
        "outputId": "daaac646-6125-4f83-cce3-f14b71f45e33"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment"
      ],
      "metadata": {
        "id": "qG4PcqhVyFmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "K4K14Xlt4LJX"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " tf.saved_model.save(model, 'saved_model')\n",
        " model.save('model.h5')"
      ],
      "metadata": {
        "id": "vv76Slt70Qpu",
        "outputId": "3da6afab-de1b-4f16-a80c-775f733d2bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, gru_cell_7_layer_call_fn, gru_cell_7_layer_call_and_return_conditional_losses, gru_cell_8_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model('saved_model')\n",
        "tflite_model = converter.convert()\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "nR-XMfSa3-pW",
        "outputId": "3dcaed0f-5d91-4961-bdc5-5043f27a104c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-c85637e60b38>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.tflite'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1245\u001b[0m           graph_def)\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_from_saved_model\u001b[0;34m(self, graph_def)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m     return self._optimize_tflite_model(\n\u001b[1;32m   1132\u001b[0m         result, quant_mode, quant_io=self.experimental_new_quantizer)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert_saved_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m   \u001b[0mmodel_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m   \u001b[0mconversion_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_conversion_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m   data = convert(\n\u001b[0m\u001b[1;32m    833\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mconversion_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model_flags_str, conversion_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0merror_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_metrics_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_collected_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m   return _run_deprecated_conversion_binary(model_flags_str,\n",
            "\u001b[0;31mConverterError\u001b[0m: <unknown>:0: error: loc(callsite(callsite(callsite(fused[\"TensorListReserve:\", \"TensorArrayV2_1@__inference_standard_gru_258128\"] at fused[\"PartitionedCall:\", \"sequential_1/bidirectional_2/backward_gru_2/PartitionedCall@__inference__wrapped_model_259122\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_269201\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: error: loc(callsite(callsite(callsite(fused[\"TensorListReserve:\", \"TensorArrayV2_1@__inference_standard_gru_258128\"] at fused[\"PartitionedCall:\", \"sequential_1/bidirectional_2/backward_gru_2/PartitionedCall@__inference__wrapped_model_259122\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_269201\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "URSzoViF6d0X"
      },
      "execution_count": 145,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VeUKsk6Xc96m",
        "yuvN6YvqdOr5",
        "wuUyzP-PdmZu",
        "z_Sk8mp7jdzH",
        "XJPg4SNldKo-",
        "Hkha78ZLhD8n",
        "j0j16iy7iI-m",
        "ldaN0eawl5v5",
        "qG4PcqhVyFmy"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}